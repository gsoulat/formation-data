# Ã‰tape 4 : Transformation Silver â†’ Gold (ModÃ¨le dimensionnel)

**DurÃ©e estimÃ©e :** 75-90 minutes  
**DifficultÃ© :** â­â­â­ AvancÃ©

---

## ğŸ¯ Objectifs

- âœ… Comprendre le modÃ¨le dimensionnel (Star Schema)
- âœ… CrÃ©er les 4 tables de dimension
- âœ… CrÃ©er la table de faits
- âœ… Charger toutes les tables dans le Lakehouse Gold
- âœ… VÃ©rifier l'intÃ©gritÃ© rÃ©fÃ©rentielle
- âœ… Documenter le modÃ¨le de donnÃ©es

---

## ğŸ“‹ PrÃ©requis

- âœ… [Ã‰tape 3 : Transformation Silver](Etape_3_Transformation_Silver.md) complÃ©tÃ©e
- âœ… DonnÃ©es enrichies dans le Lakehouse Silver

---

## ğŸ“š Comprendre le modÃ¨le dimensionnel

![SchÃ©ma de transformation](images/schema_transformation_silver_to_gold.png)
*Figure : SchÃ©ma de transformation Silver â†’ Gold (Current model vs Destination model)*

### Le Star Schema

Le **Star Schema** organise les donnÃ©es en :
- **Tables de dimension** : DÃ©crivent les contextes (qui, quoi, quand, oÃ¹)
- **Table de faits** : Contient les mesures quantitatives

```
       dim_date          dim_time
          â”‚                 â”‚
          â””â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”˜
               â”‚      â”‚
          fact_wind_power
               â”‚      â”‚
          â”Œâ”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”
          â”‚                â”‚
    dim_turbine    dim_operational_status
```

### Tables Ã  crÃ©er

**Dimensions :**
1. **dim_date** : Informations calendaires
2. **dim_time** : Informations horaires
3. **dim_turbine** : CaractÃ©ristiques des turbines
4. **dim_operational_status** : Statuts opÃ©rationnels

**Fait :**
- **fact_wind_power** : Mesures de production

---

## ğŸ’» TÃ¢che 1 : CrÃ©er le notebook Gold

1. **Nouveau Notebook** : `NB_Silver_To_Gold_Transformations_Python`
2. **Attacher** : `LH_Wind_Power_Silver` (lecture) et `LH_Wind_Power_Gold` (Ã©criture)

### Cellule Markdown : Documentation

```markdown
# Transformation Silver â†’ Gold

## ğŸ“‹ Objectif
CrÃ©er un modÃ¨le dimensionnel (star schema) optimisÃ© pour l'analyse.

## ğŸŒŸ ModÃ¨le crÃ©Ã©
- **4 dimensions** : Date, Time, Turbine, Operational Status
- **1 fait** : Production Ã©olienne

## ğŸ“¦ DÃ©pendances
- **Input** : LH_Wind_Power_Silver.dbo.wind_power
- **Output** : LH_Wind_Power_Gold (5 tables)
```

---

## ğŸ“ TÃ¢che 2 : CrÃ©er les dimensions

### Cellule 1 : Imports

```python
from pyspark.sql.window import Window
from pyspark.sql.functions import row_number, col
```

### Cellule 2 : Charger depuis Silver

```python
silver_table_path = "abfss://WindPowerAnalytics@onelake.dfs.fabric.microsoft.com/LH_Wind_Power_Silver.Lakehouse/Tables/dbo/wind_power"

df = spark.read.format("delta").load(silver_table_path)

print(f"ğŸ“Š DonnÃ©es chargÃ©es : {df.count()} lignes")
```

### Cellule 3 : dim_date

```python
# CrÃ©er dim_date avec valeurs uniques
date_dim = (df
    .select("date", "day", "month", "quarter", "year")
    .distinct()
    .withColumnRenamed("date", "date_id")
)

print(f"ğŸ“… dim_date : {date_dim.count()} dates uniques")
date_dim.show(5)
```

### Cellule 4 : dim_time

```python
# CrÃ©er dim_time avec valeurs uniques
time_dim = (df
    .select("time", "hour_of_day", "minute_of_hour", "second_of_minute", "time_period")
    .distinct()
    .withColumnRenamed("time", "time_id")
)

print(f"â° dim_time : {time_dim.count()} temps uniques")
time_dim.show(5)
```

### Cellule 5 : dim_turbine (avec surrogate key)

```python
# CrÃ©er dim_turbine avec ID auto-incrÃ©mentÃ©
turbine_dim = (df
    .select("turbine_name", "capacity", "location_name", "latitude", "longitude", "region")
    .distinct()
    .withColumn("turbine_id", 
        row_number().over(
            Window.orderBy("turbine_name", "capacity", "location_name")
        )
    )
)

print(f"ğŸŒ¬ï¸ dim_turbine : {turbine_dim.count()} turbines")
turbine_dim.show()
```

### Cellule 6 : dim_operational_status

```python
# CrÃ©er dim_operational_status avec ID
operational_status_dim = (df
    .select("status", "responsible_department")
    .distinct()
    .withColumn("status_id", 
        row_number().over(
            Window.orderBy("status", "responsible_department")
        )
    )
)

print(f"ğŸ“Š dim_operational_status : {operational_status_dim.count()} statuts")
operational_status_dim.show()
```

---

## ğŸ¯ TÃ¢che 3 : CrÃ©er la table de faits

### Cellule 7 : Joindre les dimensions

```python
# Joindre pour rÃ©cupÃ©rer les clÃ©s Ã©trangÃ¨res
df_with_keys = (df
    .join(turbine_dim, 
          ["turbine_name", "capacity", "location_name", "latitude", "longitude", "region"], 
          "left")
    .join(operational_status_dim, 
          ["status", "responsible_department"], 
          "left")
)
```

### Cellule 8 : CrÃ©er fact_wind_power

```python
# Table de faits avec uniquement clÃ©s et mesures
fact_table = (df_with_keys
    .select(
        "production_id",
        col("date").alias("date_id"),
        col("time").alias("time_id"),
        "turbine_id",
        "status_id",
        "wind_speed",
        "wind_direction",
        "energy_produced"
    )
)

print(f"ğŸ“ˆ fact_wind_power : {fact_table.count()} mesures")
fact_table.show(10)
```

---

## ğŸ’¾ TÃ¢che 4 : Sauvegarder dans Gold

### Cellule 9 : Chemins Gold

```python
base_path = "abfss://WindPowerAnalytics@onelake.dfs.fabric.microsoft.com/LH_Wind_Power_Gold.Lakehouse/Tables/dbo"

gold_date_dim_path = f"{base_path}/dim_date"
gold_time_dim_path = f"{base_path}/dim_time"
gold_turbine_dim_path = f"{base_path}/dim_turbine"
gold_operational_status_dim_path = f"{base_path}/dim_operational_status"
gold_fact_table_path = f"{base_path}/fact_wind_power"
```

### Cellule 10 : Sauvegarde

```python
# Sauvegarder toutes les tables
date_dim.write.format("delta").mode("overwrite").save(gold_date_dim_path)
time_dim.write.format("delta").mode("overwrite").save(gold_time_dim_path)
turbine_dim.write.format("delta").mode("overwrite").save(gold_turbine_dim_path)
operational_status_dim.write.format("delta").mode("overwrite").save(gold_operational_status_dim_path)
fact_table.write.format("delta").mode("overwrite").save(gold_fact_table_path)

print("âœ… Toutes les tables crÃ©Ã©es dans Gold !")
```

---

## âœ… VÃ©rifications

### Cellule 11 : IntÃ©gritÃ© rÃ©fÃ©rentielle

```python
from pyspark.sql.functions import count

print("=== ğŸ” VÃ©rification intÃ©gritÃ© rÃ©fÃ©rentielle ===\n")

# VÃ©rifier les dates
fact_dates = fact_table.select("date_id").distinct().count()
dim_dates = date_dim.count()
print(f"ğŸ“… Dates - Fait: {fact_dates}, Dim: {dim_dates}")

# VÃ©rifier les turbines
fact_turbines = fact_table.select("turbine_id").distinct().count()
dim_turbines = turbine_dim.count()
print(f"ğŸŒ¬ï¸ Turbines - Fait: {fact_turbines}, Dim: {dim_turbines}")

# VÃ©rifier les clÃ©s nulles
null_check = fact_table.select([
    count(when(col(c).isNull(), c)).alias(c) 
    for c in ["date_id", "time_id", "turbine_id", "status_id"]
])
print("\nâŒ ClÃ©s nulles dans fact :")
null_check.show()
```

---

## ğŸ“¸ Captures d'Ã©cran

1. `04_gold_lakehouse_tables.png` - Les 5 tables dans Gold
2. `04_fact_table_preview.png` - AperÃ§u de fact_wind_power
3. `04_dim_turbine_preview.png` - AperÃ§u de dim_turbine

---

## ğŸ—‚ï¸ Versionner sur GitHub

```bash
git add notebooks/gold/NB_Silver_To_Gold_Transformations_Python.ipynb
git commit -m "feat: Add Gold layer dimensional model"
git push
```

---

## âœ… VÃ©rification

- [ ] 5 tables crÃ©Ã©es dans Gold
- [ ] IntÃ©gritÃ© rÃ©fÃ©rentielle validÃ©e
- [ ] Pas de clÃ©s nulles dans fact
- [ ] Notebook documentÃ© et versionnÃ©

---

## ğŸ¯ Prochaine Ã©tape

â¡ï¸ **[Ã‰tape 5 : Orchestration Pipeline](Etape_5_Orchestration_Pipeline.md)**

*Ã‰tape 4 complÃ©tÃ©e âœ… | Temps : ~90 min | Total : ~300 min (~5h)*
