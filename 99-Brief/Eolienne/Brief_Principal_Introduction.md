# Brief Projet : Pipeline de donnÃ©es avec Microsoft Fabric
## Analyse de la production d'Ã©nergie Ã©olienne

---

## ğŸ“‹ Informations gÃ©nÃ©rales

**DurÃ©e estimÃ©e :** 2 jours  
**ModalitÃ© :** Travail individuel  
**Niveau :** DÃ©butant en Microsoft Fabric avec connaissances SQL de base  
**Plateforme :** Microsoft Fabric (version trial)

---

## ğŸ¯ Objectifs pÃ©dagogiques

Ã€ l'issue de ce projet, vous serez capable de :

1. **Mettre en place un environnement Microsoft Fabric** complet (Workspace, Lakehouses)
2. **ImplÃ©menter une architecture Medallion** (Bronze/Silver/Gold) pour le traitement de donnÃ©es
3. **DÃ©velopper des notebooks PySpark** pour les transformations de donnÃ©es
4. **Orchestrer un pipeline de donnÃ©es** avec Data Factory
5. **CrÃ©er un modÃ¨le sÃ©mantique dimensionnel** (star schema)
6. **Construire des rapports Power BI** pour visualiser les donnÃ©es transformÃ©es
7. **Documenter et versionner votre travail** avec Git/GitHub

---

## ğŸ“š Contexte du projet

Vous Ãªtes data engineer dans une entreprise de production d'Ã©nergie renouvelable. Votre mission est de crÃ©er une pipeline complÃ¨te d'analyse de la production d'Ã©oliennes. Les donnÃ©es proviennent de plusieurs turbines Ã©oliennes qui enregistrent leur production en temps rÃ©el.

### DonnÃ©es sources

Les donnÃ©es sont disponibles sur un repository GitHub public et contiennent :
- **Date** et **heure** de production
- **Nom de la turbine** et caractÃ©ristiques techniques
- **Localisation gÃ©ographique** (latitude, longitude, rÃ©gion)
- **Conditions de vent** (vitesse, direction)
- **Production d'Ã©nergie** (en kWh)
- **Statut opÃ©rationnel** et dÃ©partement responsable

**Source des donnÃ©es :** https://github.com/gsoulat/data-training-fabric/tree/main/eolienne

---

## ğŸ—ï¸ Architecture cible

Vous allez implÃ©menter une **architecture Medallion** en trois couches :

### ğŸ¥‰ Bronze Layer (DonnÃ©es brutes)
- Ingestion des donnÃ©es CSV depuis GitHub
- Stockage des donnÃ©es brutes sans transformation
- Conservation du format et de la structure d'origine

### ğŸ¥ˆ Silver Layer (DonnÃ©es nettoyÃ©es)
- Nettoyage et standardisation des donnÃ©es
- Enrichissement avec des colonnes calculÃ©es (jour, mois, annÃ©e, pÃ©riode de la journÃ©e)
- Correction des formats (time avec ":" au lieu de "-")
- Arrondi des valeurs numÃ©riques

### ğŸ¥‡ Gold Layer (DonnÃ©es mÃ©tier)
- ModÃ¨le dimensionnel (star schema) optimisÃ© pour l'analyse
- Tables de dimensions : Date, Time, Turbine, Operational Status
- Table de faits : Production d'Ã©nergie
- PrÃªt pour la consommation par Power BI

![Architecture Medallion](images/architecture_medallion_complete.png)
*Figure : Architecture complÃ¨te de la pipeline Medallion*

---

## ğŸ“ Structure du projet

Le projet est organisÃ© en **10 Ã©tapes principales**, chacune dÃ©taillÃ©e dans un fichier sÃ©parÃ© :

1. **[Ã‰tape 0 : PrÃ©paration de l'environnement](Etape_0_Preparation_Environnement.md)**
   - Obtenir un trial Microsoft Fabric
   - CrÃ©er le Workspace
   - PrÃ©parer Git/GitHub

2. **[Ã‰tape 1 : CrÃ©ation des Lakehouses](Etape_1_Creation_Lakehouses.md)**
   - Comprendre le concept de Lakehouse
   - CrÃ©er les 3 Lakehouses (Bronze, Silver, Gold)


3. **[Ã‰tape 2 : Transformation Bronze â†’ Silver](Etape_2_Transformation_Silver.md)**
   - Comprendre les transformations Silver
   - CrÃ©er les notebooks de transformation (PySpark et SQL)
   - Nettoyer et enrichir les donnÃ©es

4. **[Ã‰tape 3 : Transformation Silver â†’ Gold](Etape_3_Transformation_Gold.md)**
   - Comprendre le modÃ¨le dimensionnel
   - CrÃ©er les tables de dimension
   - CrÃ©er la table de faits

5. **[Ã‰tape 4 : CrÃ©ation du Semantic Model](Etape_4_Semantic_Model.md)**
   - CrÃ©er le Semantic Model
   - DÃ©finir les relations
   - CrÃ©er les mesures DAX
   - Organiser et formater

6. **[Ã‰tape 5 : CrÃ©ation des rapports Power BI](Etape_5_Rapports_PowerBI.md)**
   - CrÃ©er un rapport auto-gÃ©nÃ©rÃ©
   - CrÃ©er un rapport personnalisÃ©
   - Ajouter des visuels et interactivitÃ©

7. **[Ã‰tape 6 : Ingestion des donnÃ©es (Bronze)](Etape_6_Ingestion_Bronze.md)**
   - CrÃ©er le notebook d'ingestion
   - Logique d'ingestion incrÃ©mentale
   - Initialiser la table Bronze

8. **[Ã‰tape 7 : Orchestration avec Pipeline](Etape_7_Orchestration_Pipeline.md)**
   - CrÃ©er la Data Pipeline
   - Ajouter les activitÃ©s Notebook
   - DÃ©finir l'ordre d'exÃ©cution
   - Planifier l'exÃ©cution automatique
---

## ğŸ“ Livrables attendus

Ã€ la fin du projet, vous devrez fournir :

### 1. **Repository GitHub** contenant :
   - âœ… Tous les notebooks dÃ©veloppÃ©s (.ipynb)
   - âœ… Documentation complÃ¨te du projet (README.md)
   - âœ… SchÃ©ma de l'architecture rÃ©alisÃ©e
   - âœ… Instructions pour reproduire le projet


---

## ğŸ”§ PrÃ©requis techniques

### Connaissances requises
- âœ… Notions de SQL
- âœ… ComprÃ©hension des concepts de base de donnÃ©es
- âœ… FamiliaritÃ© avec les interfaces web
- âœ… Compte GitHub (Ã  crÃ©er si nÃ©cessaire)

### AccÃ¨s et outils
- ğŸŒ Navigateur web moderne (Chrome, Edge, Firefox)
- ğŸ“§ Compte Microsoft (personnel ou professionnel)
- ğŸ†“ Trial Microsoft Fabric (instructions dans l'Ã‰tape 0)
- ğŸ’» Git installÃ© localement (optionnel mais recommandÃ©)

---

## â±ï¸ Planning recommandÃ© (2 jours)

### Jour 1 - Matin (3-4h)
- âœ… Ã‰tape 0 : PrÃ©paration de l'environnement
- âœ… Ã‰tape 1 : CrÃ©ation des Lakehouses
- âœ… Ã‰tape 2 : Ingestion des donnÃ©es (Bronze)

### Jour 1 - AprÃ¨s-midi (3-4h)
- âœ… Ã‰tape 3 : Transformation Bronze â†’ Silver
- âœ… Ã‰tape 4 : Transformation Silver â†’ Gold

### Jour 2 - Matin (3-4h)
- âœ… Ã‰tape 5 : Orchestration avec Pipeline
- âœ… Ã‰tape 6 : CrÃ©ation du Semantic Model
- âœ… Ã‰tape 7 : CrÃ©ation des rapports Power BI

### Jour 2 - AprÃ¨s-midi (3-4h)
- âœ… Ã‰tape 8 : VidÃ©o de dÃ©monstration
- âœ… Ã‰tape 9 : Documentation finale et GitHub
- âœ… Ã‰tape 10 : Validation finale

---

## ğŸ“ CompÃ©tences dÃ©veloppÃ©es

Ã€ l'issue de ce projet, vous aurez dÃ©veloppÃ© les compÃ©tences suivantes :

- âœ… **Architecture de donnÃ©es** : MaÃ®trise de l'architecture Medallion (Bronze/Silver/Gold)
- âœ… **ModÃ©lisation dimensionnelle** : CrÃ©ation de schÃ©mas en Ã©toile (Star Schema)
- âœ… **PySpark** : Transformations distribuÃ©es de donnÃ©es
- âœ… **SQL** : RequÃªtes et transformations dÃ©claratives
- âœ… **Orchestration** : Automatisation de pipelines de donnÃ©es
- âœ… **Power BI** : Visualisation et reporting interactif
- âœ… **DAX** : Mesures et calculs analytiques
- âœ… **Microsoft Fabric** : Utilisation de l'Ã©cosystÃ¨me complet
- âœ… **Delta Lake** : Formats transactionnels pour data lakes
- âœ… **Git/GitHub** : Versioning et collaboration sur le code
- âœ… **Documentation technique** : Communication professionnelle

---

## ğŸ¯ CritÃ¨res de rÃ©ussite

### Niveau minimum (Validation du projet)
Pour valider ce projet, vous devez au minimum :

âœ… Avoir crÃ©Ã© les 3 Lakehouses (Bronze, Silver, Gold)  
âœ… Avoir au moins 1 notebook fonctionnel pour chaque couche  
âœ… Avoir une Pipeline qui s'exÃ©cute sans erreur  
âœ… Avoir crÃ©Ã© un Semantic Model avec relations  
âœ… Avoir au moins 1 rapport Power BI fonctionnel  
âœ… Avoir un repository GitHub avec les notebooks  
âœ… Avoir une vidÃ©o de dÃ©monstration  
âœ… Avoir un README.md basique

### Niveau attendu (Projet de qualitÃ©)
Pour un projet professionnel :

âœ… Tous les critÃ¨res du niveau minimum  
âœ… Pipeline orchestrÃ©e avec toutes les Ã©tapes  
âœ… ModÃ¨le dimensionnel complet (4 dimensions + 1 fait)  
âœ… 2 rapports Power BI (auto + manuel)  
âœ… Documentation technique complÃ¨te  
âœ… Captures d'Ã©cran de tous les composants  
âœ… VidÃ©o claire et bien structurÃ©e (5-10 min)  
âœ… Code commentÃ© et bien organisÃ©  
âœ… Commits Git rÃ©guliers avec messages clairs

### Niveau excellent (Excellence)
Pour aller au-delÃ  :

âœ… Tous les critÃ¨res du niveau attendu  
âœ… Notebooks en PySpark ET SQL  
âœ… Mesures DAX avancÃ©es (time intelligence, etc.)  
âœ… Rapports Power BI avec plusieurs pages et interactivitÃ© avancÃ©e  
âœ… Documentation exhaustive avec diagrammes professionnels  
âœ… Guide de troubleshooting dÃ©taillÃ©  
âœ… Tests de qualitÃ© de donnÃ©es implÃ©mentÃ©s  
âœ… Planification automatique de la pipeline  
âœ… VidÃ©o avec montage professionnel  
âœ… Repository GitHub avec badges, CONTRIBUTING.md, etc.

---

## ğŸ“– Ressources complÃ©mentaires

### Documentation officielle
- [Microsoft Fabric](https://learn.microsoft.com/fabric/)
- [Delta Lake](https://docs.delta.io/)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [Power BI](https://learn.microsoft.com/power-bi/)
- [DAX](https://learn.microsoft.com/dax/)

### Formations en ligne
- [Microsoft Learn - Fabric Learning Paths](https://learn.microsoft.com/training/browse/?products=fabric)
- [Databricks Academy](https://www.databricks.com/learn/training/home)
- [SQLBI (DAX)](https://www.sqlbi.com/)

### CommunautÃ©s
- [Microsoft Fabric Community](https://community.fabric.microsoft.com/)
- [Power BI Community](https://community.powerbi.com/)
- [Stack Overflow - microsoft-fabric](https://stackoverflow.com/questions/tagged/microsoft-fabric)

---

## ğŸ’¡ Conseils avant de commencer

1. **Lisez tous les briefs d'Ã©tapes avant de commencer** pour avoir une vue d'ensemble
2. **Suivez les Ã©tapes dans l'ordre** - chaque Ã©tape dÃ©pend des prÃ©cÃ©dentes
3. **Testez frÃ©quemment** - Ne passez Ã  l'Ã©tape suivante que si la prÃ©cÃ©dente fonctionne
4. **Documentez au fur et Ã  mesure** - Ne remettez pas la documentation Ã  la fin
5. **Committez rÃ©guliÃ¨rement sur Git** - Faites des commits aprÃ¨s chaque Ã©tape majeure
6. **N'hÃ©sitez pas Ã  demander de l'aide** - Consultez la documentation et les forums
7. **GÃ©rez votre temps** - Utilisez le planning recommandÃ© comme guide
8. **Prenez des captures d'Ã©cran immÃ©diatement** - Vous en aurez besoin pour la documentation

---

## ğŸš€ PrÃªt Ã  commencer ?

Maintenant que vous avez une vue d'ensemble du projet, passez Ã  la premiÃ¨re Ã©tape :

â¡ï¸ **[Ã‰tape 0 : PrÃ©paration de l'environnement](Etape_0_Preparation_Environnement.md)**

![Workspace complet](images/workspace_fabric_complete_all_items.png)
*Figure : Vue complÃ¨te du Workspace avec tous les items du projet*

Bonne chance et excellent travail ! ğŸ’ª


*Document crÃ©Ã© le 16 novembre 2025*  
*Version 1.0 - Brief modulaire*  
*Formation Microsoft Fabric - Projet Wind Power Analytics*
