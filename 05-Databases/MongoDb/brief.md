# üçÉ Brief Pratique MongoDB - Data Engineering

**Dur√©e estim√©e :** 6 heures
**Niveau :** D√©butant √† Interm√©diaire
**Modalit√© :** Pratique individuelle

---

## üéØ Objectifs du Brief

√Ä l'issue de ce brief, vous serez capable de :
- Installer et configurer MongoDB (local et cloud)
- Ma√Ætriser les op√©rations CRUD
- Cr√©er des pipelines d'agr√©gation complexes
- Optimiser les performances avec les index
- Mod√©liser des donn√©es pour MongoDB
- Int√©grer MongoDB dans des pipelines Data Engineering Python

---

## üìã Contexte

Vous √™tes Data Engineer chez **DataStream Analytics**. L'entreprise a d√©cid√© d'adopter MongoDB pour stocker et analyser des donn√©es semi-structur√©es provenant de diverses sources (APIs, logs, IoT). Votre mission est de mettre en place une solution MongoDB compl√®te pour supporter les besoins data de l'entreprise.

---

## üöÄ Partie 1 : Installation et configuration (1h)

### T√¢che 1.1 : Installer MongoDB avec Docker

**Instructions :**

1. **Cr√©er un fichier `docker-compose.yml` :**

```yaml
version: '3.8'

services:
  mongodb:
    image: mongo:7.0
    container_name: mongodb_dev
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: SecurePass123
      MONGO_INITDB_DATABASE: dataeng
    volumes:
      - mongodb_data:/data/db
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js
    restart: unless-stopped

  mongo-express:
    image: mongo-express:latest
    container_name: mongo_express
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin
      ME_CONFIG_MONGODB_ADMINPASSWORD: SecurePass123
      ME_CONFIG_MONGODB_URL: mongodb://admin:SecurePass123@mongodb:27017/
      ME_CONFIG_BASICAUTH: false
    depends_on:
      - mongodb
    restart: unless-stopped

volumes:
  mongodb_data:
```

2. **Cr√©er un fichier `mongo-init.js` pour initialiser les donn√©es :**

```javascript
// Cr√©er un utilisateur pour la base de donn√©es dataeng
db = db.getSiblingDB('dataeng');

db.createUser({
  user: 'dataeng_user',
  pwd: 'DataPass123',
  roles: [
    {
      role: 'readWrite',
      db: 'dataeng'
    }
  ]
});

// Cr√©er une collection et ins√©rer des donn√©es de test
db.createCollection('users');

db.users.insertMany([
  {
    name: "Alice Dupont",
    email: "alice.dupont@example.com",
    age: 28,
    department: "Data Engineering",
    skills: ["Python", "SQL", "MongoDB"],
    salary: 55000,
    hire_date: new Date("2022-01-15")
  },
  {
    name: "Bob Martin",
    email: "bob.martin@example.com",
    age: 32,
    department: "Data Science",
    skills: ["Python", "R", "Machine Learning"],
    salary: 65000,
    hire_date: new Date("2020-06-20")
  },
  {
    name: "Charlie Brown",
    email: "charlie.brown@example.com",
    age: 25,
    department: "Data Engineering",
    skills: ["Java", "Spark", "Kafka"],
    salary: 50000,
    hire_date: new Date("2023-03-10")
  }
]);

print("‚úÖ Base de donn√©es initialis√©e avec succ√®s");
```

3. **Lancer les conteneurs :**

```bash
# D√©marrer MongoDB et Mongo Express
docker-compose up -d

# V√©rifier que les conteneurs sont lanc√©s
docker-compose ps

# Voir les logs
docker-compose logs mongodb
```

4. **Tester la connexion :**

```bash
# Se connecter au shell MongoDB
docker exec -it mongodb_dev mongosh -u admin -p SecurePass123

# Dans le shell MongoDB
show dbs
use dataeng
db.users.find()
exit
```

5. **Acc√©der √† Mongo Express :**
   - Ouvrir http://localhost:8081 dans le navigateur
   - Explorer la base de donn√©es graphiquement

**Crit√®res de validation :**
- ‚úÖ Conteneurs MongoDB et Mongo Express lanc√©s
- ‚úÖ Connexion r√©ussie au shell MongoDB
- ‚úÖ Donn√©es initiales visibles dans la collection users
- ‚úÖ Mongo Express accessible sur http://localhost:8081

---

### T√¢che 1.2 : Configurer l'environnement Python

**Instructions :**

1. **Cr√©er un environnement virtuel :**

```bash
# Cr√©er un dossier pour le projet
mkdir mongodb-data-engineering
cd mongodb-data-engineering

# Cr√©er un environnement virtuel
python -m venv venv

# Activer l'environnement
# macOS/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate
```

2. **Cr√©er un fichier `requirements.txt` :**

```
pymongo==4.6.0
pandas==2.1.0
python-dotenv==1.0.0
faker==20.0.0
```

3. **Installer les d√©pendances :**

```bash
pip install -r requirements.txt
```

4. **Cr√©er un fichier `.env` pour les credentials :**

```
MONGODB_URI=mongodb://admin:SecurePass123@localhost:27017/
DATABASE_NAME=dataeng
COLLECTION_NAME=users
```

5. **Cr√©er un script `test_connection.py` :**

```python
from pymongo import MongoClient
from dotenv import load_dotenv
import os

# Charger les variables d'environnement
load_dotenv()

# Connexion √† MongoDB
uri = os.getenv('MONGODB_URI')
client = MongoClient(uri)

try:
    # Tester la connexion
    client.admin.command('ping')
    print("‚úÖ Connexion √† MongoDB r√©ussie!")

    # Lister les bases de donn√©es
    dbs = client.list_database_names()
    print(f"üìö Bases de donn√©es disponibles: {dbs}")

    # Acc√©der √† la base de donn√©es
    db = client[os.getenv('DATABASE_NAME')]

    # Lister les collections
    collections = db.list_collection_names()
    print(f"üìÅ Collections: {collections}")

    # Compter les documents dans users
    count = db.users.count_documents({})
    print(f"üë• Nombre d'utilisateurs: {count}")

    # Afficher un utilisateur
    user = db.users.find_one()
    print(f"üë§ Premier utilisateur: {user['name']} - {user['email']}")

except Exception as e:
    print(f"‚ùå Erreur: {e}")

finally:
    client.close()
    print("üîí Connexion ferm√©e")
```

6. **Ex√©cuter le script :**

```bash
python test_connection.py
```

**Crit√®res de validation :**
- ‚úÖ Environnement virtuel cr√©√© et activ√©
- ‚úÖ D√©pendances install√©es
- ‚úÖ Script test_connection.py ex√©cut√© avec succ√®s
- ‚úÖ Connexion MongoDB fonctionnelle depuis Python

---

## üìù Partie 2 : Op√©rations CRUD et requ√™tes (1h30)

### T√¢che 2.1 : Ins√©rer des donn√©es (Create)

**Sc√©nario :** Vous devez importer des donn√©es de ventes dans MongoDB.

**Instructions :**

1. **Cr√©er un fichier `insert_data.py` :**

```python
from pymongo import MongoClient
from faker import Faker
from datetime import datetime, timedelta
import random

fake = Faker('fr_FR')

# Connexion
client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']

# Collection sales
sales_collection = db['sales']

# G√©n√©rer 100 ventes fictives
sales = []

for i in range(100):
    sale = {
        "transaction_id": f"TRX{str(i+1).zfill(5)}",
        "customer": {
            "name": fake.name(),
            "email": fake.email(),
            "city": fake.city()
        },
        "products": [
            {
                "name": random.choice(["Laptop", "Mouse", "Keyboard", "Monitor", "Headset"]),
                "quantity": random.randint(1, 5),
                "unit_price": round(random.uniform(20, 1500), 2)
            }
            for _ in range(random.randint(1, 3))
        ],
        "total_amount": 0,  # Sera calcul√©
        "payment_method": random.choice(["Credit Card", "PayPal", "Bank Transfer"]),
        "status": random.choice(["completed", "pending", "cancelled"]),
        "created_at": datetime.now() - timedelta(days=random.randint(0, 365)),
        "metadata": {
            "source": "web",
            "campaign": random.choice(["email", "social", "direct", "ads"])
        }
    }

    # Calculer le montant total
    sale['total_amount'] = sum(
        p['quantity'] * p['unit_price'] for p in sale['products']
    )

    sales.append(sale)

# Ins√©rer en bulk
result = sales_collection.insert_many(sales)
print(f"‚úÖ {len(result.inserted_ids)} ventes ins√©r√©es")

# Statistiques
total_sales = sum(s['total_amount'] for s in sales)
print(f"üí∞ Montant total des ventes: {total_sales:,.2f}‚Ç¨")

client.close()
```

2. **Ex√©cuter le script :**

```bash
python insert_data.py
```

3. **V√©rifier dans MongoDB Shell :**

```javascript
db.sales.countDocuments()
db.sales.findOne()
```

**Crit√®res de validation :**
- ‚úÖ 100 documents ins√©r√©s dans la collection sales
- ‚úÖ Structure de donn√©es correcte avec sous-documents
- ‚úÖ Montant total calcul√©

---

### T√¢che 2.2 : Requ√™tes de lecture (Read)

**Instructions :**

Cr√©ez un fichier `queries.py` avec les requ√™tes suivantes :

```python
from pymongo import MongoClient

client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']
sales = db['sales']

print("=== REQU√äTES MONGODB ===\n")

# 1. Toutes les ventes compl√©t√©es
print("1Ô∏è‚É£ Ventes compl√©t√©es:")
completed = sales.find({"status": "completed"})
print(f"   Nombre: {sales.count_documents({'status': 'completed'})}")

# 2. Ventes > 500‚Ç¨
print("\n2Ô∏è‚É£ Ventes > 500‚Ç¨:")
high_value = sales.find(
    {"total_amount": {"$gt": 500}},
    {"transaction_id": 1, "total_amount": 1, "_id": 0}
)
for sale in high_value.limit(5):
    print(f"   {sale['transaction_id']}: {sale['total_amount']:.2f}‚Ç¨")

# 3. Ventes √† Paris
print("\n3Ô∏è‚É£ Ventes √† Paris:")
paris_sales = sales.find({"customer.city": {"$regex": "Paris", "$options": "i"}})
print(f"   Nombre: {sales.count_documents({'customer.city': {'$regex': 'Paris', '$options': 'i'}})}")

# 4. Ventes par carte de cr√©dit en 2024
print("\n4Ô∏è‚É£ Ventes par carte de cr√©dit en 2024:")
from datetime import datetime
start_2024 = datetime(2024, 1, 1)
end_2024 = datetime(2024, 12, 31)

cc_sales = sales.find({
    "payment_method": "Credit Card",
    "created_at": {"$gte": start_2024, "$lte": end_2024}
})
count = sales.count_documents({
    "payment_method": "Credit Card",
    "created_at": {"$gte": start_2024, "$lte": end_2024}
})
print(f"   Nombre: {count}")

# 5. Ventes avec laptop dans les produits
print("\n5Ô∏è‚É£ Ventes contenant un Laptop:")
laptop_sales = sales.find({"products.name": "Laptop"})
print(f"   Nombre: {sales.count_documents({'products.name': 'Laptop'})}")

# 6. Top 5 ventes par montant
print("\n6Ô∏è‚É£ Top 5 ventes:")
top_sales = sales.find(
    {},
    {"transaction_id": 1, "customer.name": 1, "total_amount": 1, "_id": 0}
).sort("total_amount", -1).limit(5)

for i, sale in enumerate(top_sales, 1):
    print(f"   #{i} {sale['transaction_id']}: {sale['customer']['name']} - {sale['total_amount']:.2f}‚Ç¨")

# 7. Ventes entre 100‚Ç¨ et 300‚Ç¨
print("\n7Ô∏è‚É£ Ventes entre 100‚Ç¨ et 300‚Ç¨:")
mid_range = sales.count_documents({
    "total_amount": {"$gte": 100, "$lte": 300}
})
print(f"   Nombre: {mid_range}")

# 8. Ventes avec statut pending ou cancelled
print("\n8Ô∏è‚É£ Ventes pending ou cancelled:")
not_completed = sales.find({
    "status": {"$in": ["pending", "cancelled"]}
})
print(f"   Nombre: {sales.count_documents({'status': {'$in': ['pending', 'cancelled']}})}")

client.close()
```

**Ex√©cuter :**

```bash
python queries.py
```

**Crit√®res de validation :**
- ‚úÖ Toutes les requ√™tes s'ex√©cutent sans erreur
- ‚úÖ R√©sultats coh√©rents avec les donn√©es ins√©r√©es
- ‚úÖ Utilisation correcte des op√©rateurs ($gt, $in, $regex, etc.)

---

### T√¢che 2.3 : Mises √† jour (Update)

**Instructions :**

Cr√©ez un fichier `updates.py` :

```python
from pymongo import MongoClient
from datetime import datetime

client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']
sales = db['sales']

print("=== MISES √Ä JOUR ===\n")

# 1. Ajouter un champ updated_at √† toutes les ventes
result = sales.update_many(
    {},
    {"$set": {"updated_at": datetime.now()}}
)
print(f"1Ô∏è‚É£ Champ updated_at ajout√© √† {result.modified_count} documents")

# 2. Ajouter une remise de 10% aux ventes > 1000‚Ç¨
result = sales.update_many(
    {"total_amount": {"$gt": 1000}},
    {
        "$set": {"discount_applied": True, "discount_percent": 10},
        "$mul": {"total_amount": 0.9}
    }
)
print(f"2Ô∏è‚É£ Remise appliqu√©e √† {result.modified_count} ventes")

# 3. Changer le statut pending en processing
result = sales.update_many(
    {"status": "pending"},
    {"$set": {"status": "processing"}}
)
print(f"3Ô∏è‚É£ {result.modified_count} ventes pass√©es en processing")

# 4. Ajouter un tag "premium" aux ventes > 500‚Ç¨
result = sales.update_many(
    {"total_amount": {"$gt": 500}},
    {"$addToSet": {"tags": "premium"}}
)
print(f"4Ô∏è‚É£ Tag premium ajout√© √† {result.modified_count} ventes")

# 5. Mettre √† jour une vente sp√©cifique
result = sales.update_one(
    {"transaction_id": "TRX00001"},
    {
        "$set": {
            "status": "completed",
            "shipping_date": datetime.now(),
            "tracking_number": "TRACK123456"
        }
    }
)
print(f"5Ô∏è‚É£ Vente TRX00001 mise √† jour: {result.modified_count} document")

# 6. Incr√©menter la quantit√© d'un produit
result = sales.update_one(
    {"transaction_id": "TRX00002", "products.name": "Laptop"},
    {"$inc": {"products.$.quantity": 1}}
)
print(f"6Ô∏è‚É£ Quantit√© incr√©ment√©e: {result.modified_count} document")

# V√©rifier une mise √† jour
updated_sale = sales.find_one({"transaction_id": "TRX00001"})
print(f"\n‚úÖ V√©rification TRX00001:")
print(f"   Statut: {updated_sale.get('status')}")
print(f"   Tracking: {updated_sale.get('tracking_number')}")

client.close()
```

**Ex√©cuter :**

```bash
python updates.py
```

**Crit√®res de validation :**
- ‚úÖ Mises √† jour en masse r√©ussies
- ‚úÖ Utilisation correcte des op√©rateurs ($set, $mul, $inc, $addToSet)
- ‚úÖ Mise √† jour d'√©l√©ments dans des tableaux ($)

---

### T√¢che 2.4 : Suppressions (Delete)

**Instructions :**

Cr√©ez un fichier `deletes.py` :

```python
from pymongo import MongoClient
from datetime import datetime, timedelta

client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']
sales = db['sales']

print("=== SUPPRESSIONS ===\n")

# Compter avant suppressions
total_before = sales.count_documents({})
print(f"üìä Total avant: {total_before} documents\n")

# 1. Supprimer les ventes cancelled
result = sales.delete_many({"status": "cancelled"})
print(f"1Ô∏è‚É£ Ventes cancelled supprim√©es: {result.deleted_count}")

# 2. Supprimer les ventes < 50‚Ç¨
result = sales.delete_many({"total_amount": {"$lt": 50}})
print(f"2Ô∏è‚É£ Ventes < 50‚Ç¨ supprim√©es: {result.deleted_count}")

# 3. Supprimer les ventes de plus d'un an
one_year_ago = datetime.now() - timedelta(days=365)
result = sales.delete_many({"created_at": {"$lt": one_year_ago}})
print(f"3Ô∏è‚É£ Ventes > 1 an supprim√©es: {result.deleted_count}")

# Compter apr√®s suppressions
total_after = sales.count_documents({})
print(f"\nüìä Total apr√®s: {total_after} documents")
print(f"üóëÔ∏è Total supprim√©: {total_before - total_after} documents")

client.close()
```

**Ex√©cuter :**

```bash
python deletes.py
```

**Crit√®res de validation :**
- ‚úÖ Suppressions cibl√©es r√©ussies
- ‚úÖ Nombre de documents supprim√©s correct

---

## üìä Partie 3 : Agr√©gation et analytics (2h)

### T√¢che 3.1 : Agr√©gations simples

**Instructions :**

Cr√©ez un fichier `aggregations.py` :

```python
from pymongo import MongoClient

client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']
sales = db['sales']

print("=== AGR√âGATIONS ===\n")

# 1. Ventes par statut
print("1Ô∏è‚É£ Ventes par statut:")
pipeline1 = [
    {
        "$group": {
            "_id": "$status",
            "count": {"$sum": 1},
            "total_amount": {"$sum": "$total_amount"},
            "avg_amount": {"$avg": "$total_amount"}
        }
    },
    {"$sort": {"count": -1}}
]

for result in sales.aggregate(pipeline1):
    print(f"   {result['_id']}: {result['count']} ventes, "
          f"total: {result['total_amount']:.2f}‚Ç¨, "
          f"moyenne: {result['avg_amount']:.2f}‚Ç¨")

# 2. Top 5 villes par nombre de ventes
print("\n2Ô∏è‚É£ Top 5 villes:")
pipeline2 = [
    {
        "$group": {
            "_id": "$customer.city",
            "sales_count": {"$sum": 1},
            "total_revenue": {"$sum": "$total_amount"}
        }
    },
    {"$sort": {"sales_count": -1}},
    {"$limit": 5}
]

for result in sales.aggregate(pipeline2):
    print(f"   {result['_id']}: {result['sales_count']} ventes, "
          f"{result['total_revenue']:.2f}‚Ç¨")

# 3. Ventes par m√©thode de paiement
print("\n3Ô∏è‚É£ Ventes par m√©thode de paiement:")
pipeline3 = [
    {
        "$group": {
            "_id": "$payment_method",
            "count": {"$sum": 1},
            "percentage": {"$sum": 1}  # Sera calcul√© apr√®s
        }
    },
    {"$sort": {"count": -1}}
]

total = sales.count_documents({})
for result in sales.aggregate(pipeline3):
    percentage = (result['count'] / total) * 100
    print(f"   {result['_id']}: {result['count']} ({percentage:.1f}%)")

# 4. Statistiques globales
print("\n4Ô∏è‚É£ Statistiques globales:")
pipeline4 = [
    {
        "$group": {
            "_id": None,
            "total_sales": {"$sum": 1},
            "total_revenue": {"$sum": "$total_amount"},
            "avg_order_value": {"$avg": "$total_amount"},
            "min_order": {"$min": "$total_amount"},
            "max_order": {"$max": "$total_amount"}
        }
    }
]

stats = list(sales.aggregate(pipeline4))[0]
print(f"   Total ventes: {stats['total_sales']}")
print(f"   Chiffre d'affaires: {stats['total_revenue']:.2f}‚Ç¨")
print(f"   Panier moyen: {stats['avg_order_value']:.2f}‚Ç¨")
print(f"   Commande min: {stats['min_order']:.2f}‚Ç¨")
print(f"   Commande max: {stats['max_order']:.2f}‚Ç¨")

client.close()
```

**Ex√©cuter :**

```bash
python aggregations.py
```

**Crit√®res de validation :**
- ‚úÖ Agr√©gations simples fonctionnelles
- ‚úÖ Utilisation de $group, $sum, $avg, $min, $max
- ‚úÖ Tri et limite des r√©sultats

---

### T√¢che 3.2 : Agr√©gations complexes avec $unwind

**Instructions :**

Cr√©ez un fichier `advanced_aggregations.py` :

```python
from pymongo import MongoClient

client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']
sales = db['sales']

print("=== AGR√âGATIONS AVANC√âES ===\n")

# 1. Top 5 produits les plus vendus (n√©cessite $unwind)
print("1Ô∏è‚É£ Top 5 produits:")
pipeline1 = [
    {"$unwind": "$products"},
    {
        "$group": {
            "_id": "$products.name",
            "total_quantity": {"$sum": "$products.quantity"},
            "total_revenue": {"$sum": {"$multiply": ["$products.quantity", "$products.unit_price"]}},
            "avg_price": {"$avg": "$products.unit_price"}
        }
    },
    {"$sort": {"total_quantity": -1}},
    {"$limit": 5}
]

for result in sales.aggregate(pipeline1):
    print(f"   {result['_id']}: {result['total_quantity']} unit√©s vendues, "
          f"{result['total_revenue']:.2f}‚Ç¨, prix moyen: {result['avg_price']:.2f}‚Ç¨")

# 2. Ventes par mois (time-series)
print("\n2Ô∏è‚É£ Ventes par mois:")
pipeline2 = [
    {
        "$project": {
            "year_month": {
                "$dateToString": {
                    "format": "%Y-%m",
                    "date": "$created_at"
                }
            },
            "total_amount": 1
        }
    },
    {
        "$group": {
            "_id": "$year_month",
            "sales_count": {"$sum": 1},
            "revenue": {"$sum": "$total_amount"}
        }
    },
    {"$sort": {"_id": 1}}
]

for result in sales.aggregate(pipeline2):
    print(f"   {result['_id']}: {result['sales_count']} ventes, {result['revenue']:.2f}‚Ç¨")

# 3. Performance par campagne marketing
print("\n3Ô∏è‚É£ Performance des campagnes:")
pipeline3 = [
    {
        "$group": {
            "_id": "$metadata.campaign",
            "sales": {"$sum": 1},
            "revenue": {"$sum": "$total_amount"},
            "avg_order_value": {"$avg": "$total_amount"}
        }
    },
    {"$sort": {"revenue": -1}}
]

for result in sales.aggregate(pipeline3):
    print(f"   {result['_id']}: {result['sales']} ventes, "
          f"{result['revenue']:.2f}‚Ç¨, AOV: {result['avg_order_value']:.2f}‚Ç¨")

# 4. Analyse par tranche de prix
print("\n4Ô∏è‚É£ Ventes par tranche de prix:")
pipeline4 = [
    {
        "$bucket": {
            "groupBy": "$total_amount",
            "boundaries": [0, 100, 300, 500, 1000, 10000],
            "default": "Other",
            "output": {
                "count": {"$sum": 1},
                "total_revenue": {"$sum": "$total_amount"}
            }
        }
    }
]

ranges = ["0-100‚Ç¨", "100-300‚Ç¨", "300-500‚Ç¨", "500-1000‚Ç¨", "1000‚Ç¨+"]
for i, result in enumerate(sales.aggregate(pipeline4)):
    if i < len(ranges):
        print(f"   {ranges[i]}: {result['count']} ventes, {result['total_revenue']:.2f}‚Ç¨")

# 5. Clients avec le plus de commandes (top 5)
print("\n5Ô∏è‚É£ Top 5 clients:")
pipeline5 = [
    {
        "$group": {
            "_id": "$customer.email",
            "name": {"$first": "$customer.name"},
            "orders_count": {"$sum": 1},
            "total_spent": {"$sum": "$total_amount"}
        }
    },
    {"$sort": {"orders_count": -1}},
    {"$limit": 5}
]

for result in sales.aggregate(pipeline5):
    print(f"   {result['name']} ({result['_id']}): "
          f"{result['orders_count']} commandes, {result['total_spent']:.2f}‚Ç¨")

client.close()
```

**Ex√©cuter :**

```bash
python advanced_aggregations.py
```

**Crit√®res de validation :**
- ‚úÖ $unwind utilis√© pour d√©rouler les produits
- ‚úÖ Agr√©gations temporelles avec $dateToString
- ‚úÖ $bucket pour cr√©er des tranches
- ‚úÖ Pipelines multi-stages fonctionnels

---

### T√¢che 3.3 : Export des r√©sultats vers CSV

**Instructions :**

Cr√©ez un fichier `export_analytics.py` :

```python
from pymongo import MongoClient
import pandas as pd
from datetime import datetime

client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']
sales = db['sales']

print("=== EXPORT ANALYTICS ===\n")

# 1. Export des ventes en DataFrame
sales_data = list(sales.find({}, {
    "transaction_id": 1,
    "customer.name": 1,
    "customer.city": 1,
    "total_amount": 1,
    "status": 1,
    "created_at": 1,
    "_id": 0
}))

df = pd.DataFrame(sales_data)

# Aplatir les donn√©es nested
df['customer_name'] = df['customer'].apply(lambda x: x['name'])
df['customer_city'] = df['customer'].apply(lambda x: x['city'])
df = df.drop('customer', axis=1)

print(f"üìä DataFrame cr√©√©: {len(df)} lignes\n")
print(df.head())

# Export vers CSV
df.to_csv('sales_export.csv', index=False)
print(f"\n‚úÖ Export CSV: sales_export.csv")

# 2. Analytics dashboard data
pipeline = [
    {
        "$group": {
            "_id": {
                "status": "$status",
                "payment_method": "$payment_method"
            },
            "count": {"$sum": 1},
            "revenue": {"$sum": "$total_amount"}
        }
    }
]

analytics_data = list(sales.aggregate(pipeline))
analytics_df = pd.DataFrame(analytics_data)

# Restructurer les donn√©es
analytics_df['status'] = analytics_df['_id'].apply(lambda x: x['status'])
analytics_df['payment_method'] = analytics_df['_id'].apply(lambda x: x['payment_method'])
analytics_df = analytics_df.drop('_id', axis=1)

analytics_df.to_csv('sales_analytics.csv', index=False)
print(f"‚úÖ Export analytics: sales_analytics.csv")

# 3. Statistiques produits
products_pipeline = [
    {"$unwind": "$products"},
    {
        "$group": {
            "_id": "$products.name",
            "total_quantity": {"$sum": "$products.quantity"},
            "total_revenue": {
                "$sum": {
                    "$multiply": ["$products.quantity", "$products.unit_price"]
                }
            },
            "avg_price": {"$avg": "$products.unit_price"}
        }
    },
    {"$sort": {"total_revenue": -1}}
]

products_data = list(sales.aggregate(products_pipeline))
products_df = pd.DataFrame(products_data)
products_df = products_df.rename(columns={'_id': 'product_name'})

products_df.to_csv('products_analytics.csv', index=False)
print(f"‚úÖ Export produits: products_analytics.csv")

print(f"\nüìÅ Fichiers cr√©√©s:")
print(f"   - sales_export.csv ({len(df)} lignes)")
print(f"   - sales_analytics.csv ({len(analytics_df)} lignes)")
print(f"   - products_analytics.csv ({len(products_df)} lignes)")

client.close()
```

**Ex√©cuter :**

```bash
python export_analytics.py
```

**Crit√®res de validation :**
- ‚úÖ DataFrames Pandas cr√©√©s depuis MongoDB
- ‚úÖ 3 fichiers CSV export√©s
- ‚úÖ Donn√©es correctement aplaties (nested ‚Üí flat)

---

## ‚ö° Partie 4 : Performances et index (1h)

### T√¢che 4.1 : Analyser les performances

**Instructions :**

Cr√©ez un fichier `performance_analysis.py` :

```python
from pymongo import MongoClient
import time

client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']
sales = db['sales']

print("=== ANALYSE DES PERFORMANCES ===\n")

# 1. Mesurer une requ√™te sans index
print("1Ô∏è‚É£ Requ√™te SANS index:")
start = time.time()
result = sales.find({"customer.email": "alice.dupont@example.com"})
list(result)  # Force l'ex√©cution
duration = time.time() - start
print(f"   Temps d'ex√©cution: {duration*1000:.2f}ms")

# Explain de la requ√™te
explain = sales.find({"customer.email": "alice.dupont@example.com"}).explain()
print(f"   Documents examin√©s: {explain['executionStats']['totalDocsExamined']}")
print(f"   Temps (serveur): {explain['executionStats']['executionTimeMillis']}ms")
print(f"   Type de scan: {explain['executionStats']['executionStages']['stage']}")

# 2. Cr√©er des index
print("\n2Ô∏è‚É£ Cr√©ation des index:")

# Index sur email
sales.create_index([("customer.email", 1)])
print("   ‚úÖ Index cr√©√© sur customer.email")

# Index sur total_amount
sales.create_index([("total_amount", -1)])
print("   ‚úÖ Index cr√©√© sur total_amount")

# Index compos√©
sales.create_index([("status", 1), ("created_at", -1)])
print("   ‚úÖ Index compos√© cr√©√© sur status + created_at")

# Index sur transaction_id (unique)
sales.create_index([("transaction_id", 1)], unique=True)
print("   ‚úÖ Index unique cr√©√© sur transaction_id")

# 3. Mesurer la m√™me requ√™te AVEC index
print("\n3Ô∏è‚É£ Requ√™te AVEC index:")
start = time.time()
result = sales.find({"customer.email": "alice.dupont@example.com"})
list(result)
duration = time.time() - start
print(f"   Temps d'ex√©cution: {duration*1000:.2f}ms")

explain = sales.find({"customer.email": "alice.dupont@example.com"}).explain()
print(f"   Documents examin√©s: {explain['executionStats']['totalDocsExamined']}")
print(f"   Temps (serveur): {explain['executionStats']['executionTimeMillis']}ms")
print(f"   Index utilis√©: {explain['executionStats']['executionStages'].get('indexName', 'N/A')}")

# 4. Lister tous les index
print("\n4Ô∏è‚É£ Index de la collection:")
for index in sales.list_indexes():
    print(f"   - {index['name']}: {index['key']}")

# 5. Tester une requ√™te complexe
print("\n5Ô∏è‚É£ Requ√™te complexe optimis√©e:")
pipeline = [
    {
        "$match": {
            "status": "completed",
            "total_amount": {"$gt": 200}
        }
    },
    {
        "$group": {
            "_id": "$customer.city",
            "count": {"$sum": 1}
        }
    },
    {"$sort": {"count": -1}},
    {"$limit": 5}
]

start = time.time()
result = list(sales.aggregate(pipeline))
duration = time.time() - start

print(f"   Temps d'ex√©cution: {duration*1000:.2f}ms")
print(f"   R√©sultats: {len(result)} villes")

client.close()
```

**Ex√©cuter :**

```bash
python performance_analysis.py
```

**Crit√®res de validation :**
- ‚úÖ Diff√©rence de performance mesurable avant/apr√®s index
- ‚úÖ 4 index cr√©√©s (simple, compos√©, unique)
- ‚úÖ explain() utilis√© pour analyser les requ√™tes
- ‚úÖ Am√©lioration visible des temps d'ex√©cution

---

### T√¢che 4.2 : Optimiser les agr√©gations

**Instructions :**

Cr√©ez un fichier `optimize_aggregations.py` :

```python
from pymongo import MongoClient
import time

client = MongoClient('mongodb://admin:SecurePass123@localhost:27017/')
db = client['dataeng']
sales = db['sales']

print("=== OPTIMISATION DES AGR√âGATIONS ===\n")

# Pipeline NON optimis√© (match apr√®s group)
print("1Ô∏è‚É£ Pipeline NON optimis√©:")
pipeline_bad = [
    {
        "$group": {
            "_id": "$status",
            "total": {"$sum": "$total_amount"}
        }
    },
    {
        "$match": {
            "_id": "completed"
        }
    }
]

start = time.time()
result = list(sales.aggregate(pipeline_bad))
duration = time.time() - start
print(f"   Temps: {duration*1000:.2f}ms")

# Pipeline OPTIMIS√â (match avant group)
print("\n2Ô∏è‚É£ Pipeline OPTIMIS√â:")
pipeline_good = [
    {
        "$match": {
            "status": "completed"
        }
    },
    {
        "$group": {
            "_id": "$status",
            "total": {"$sum": "$total_amount"}
        }
    }
]

start = time.time()
result = list(sales.aggregate(pipeline_good))
duration = time.time() - start
print(f"   Temps: {duration*1000:.2f}ms")
print("   üí° $match avant $group r√©duit les documents √† traiter")

# Pipeline avec projection
print("\n3Ô∏è‚É£ Pipeline avec $project:")
pipeline_project = [
    {
        "$match": {
            "status": "completed"
        }
    },
    {
        "$project": {
            "total_amount": 1,
            "customer.city": 1
        }
    },
    {
        "$group": {
            "_id": "$customer.city",
            "revenue": {"$sum": "$total_amount"}
        }
    },
    {"$sort": {"revenue": -1}},
    {"$limit": 10}
]

start = time.time()
result = list(sales.aggregate(pipeline_project))
duration = time.time() - start
print(f"   Temps: {duration*1000:.2f}ms")
print("   üí° $project r√©duit la taille des documents")

# Utiliser allowDiskUse pour les gros datasets
print("\n4Ô∏è‚É£ Pipeline avec allowDiskUse:")
pipeline_large = [
    {"$unwind": "$products"},
    {
        "$group": {
            "_id": {
                "product": "$products.name",
                "city": "$customer.city"
            },
            "count": {"$sum": 1}
        }
    },
    {"$sort": {"count": -1}}
]

result = sales.aggregate(pipeline_large, allowDiskUse=True)
print("   ‚úÖ allowDiskUse=True pour les agr√©gations gourmandes en m√©moire")

client.close()
```

**Ex√©cuter :**

```bash
python optimize_aggregations.py
```

**Crit√®res de validation :**
- ‚úÖ Comparaison de pipelines optimis√©s vs non-optimis√©s
- ‚úÖ $match plac√© avant $group
- ‚úÖ $project utilis√© pour r√©duire la taille des documents
- ‚úÖ allowDiskUse utilis√©

---

## üèóÔ∏è Partie 5 : Projet final - Pipeline ETL complet (1h30)

### T√¢che 5.1 : Cr√©er un pipeline ETL production-ready

**Sc√©nario final :** Cr√©ez un pipeline ETL complet qui :
1. Extrait des donn√©es d'une API
2. Transforme et valide les donn√©es
3. Charge dans MongoDB avec gestion d'erreurs
4. G√©n√®re des rapports analytics
5. Log toutes les op√©rations

**Instructions :**

Cr√©ez un fichier `etl_pipeline.py` :

```python
"""
Pipeline ETL Production-Ready pour MongoDB
Extract ‚Üí Transform ‚Üí Load ‚Üí Analyze
"""

from pymongo import MongoClient
import requests
from datetime import datetime
import logging
import json
import pandas as pd
from typing import Dict, List, Any

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('etl_pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class MongoDBETLPipeline:
    """Pipeline ETL pour MongoDB"""

    def __init__(self, mongo_uri: str, database: str):
        self.mongo_uri = mongo_uri
        self.database_name = database
        self.client = None
        self.db = None
        self.stats = {
            "extracted": 0,
            "transformed": 0,
            "loaded": 0,
            "errors": 0
        }

    def connect(self):
        """Connexion √† MongoDB"""
        try:
            self.client = MongoClient(self.mongo_uri)
            self.db = self.client[self.database_name]
            self.client.admin.command('ping')
            logger.info(f"‚úÖ Connect√© √† MongoDB: {self.database_name}")
        except Exception as e:
            logger.error(f"‚ùå Erreur de connexion MongoDB: {e}")
            raise

    def disconnect(self):
        """D√©connexion de MongoDB"""
        if self.client:
            self.client.close()
            logger.info("üîí Connexion MongoDB ferm√©e")

    def extract_from_api(self, api_url: str) -> List[Dict]:
        """Extract: R√©cup√©rer les donn√©es depuis une API"""
        logger.info(f"üì• Extraction depuis {api_url}")

        try:
            response = requests.get(api_url, timeout=30)
            response.raise_for_status()

            data = response.json()
            self.stats["extracted"] = len(data)

            logger.info(f"‚úÖ {self.stats['extracted']} enregistrements extraits")
            return data

        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erreur lors de l'extraction: {e}")
            self.stats["errors"] += 1
            return []

    def validate_record(self, record: Dict) -> bool:
        """Valider un enregistrement"""
        required_fields = ['name', 'email', 'address']

        # V√©rifier les champs requis
        for field in required_fields:
            if field not in record or not record[field]:
                logger.warning(f"‚ö†Ô∏è Champ manquant: {field}")
                return False

        # Valider l'email
        if '@' not in record.get('email', ''):
            logger.warning(f"‚ö†Ô∏è Email invalide: {record.get('email')}")
            return False

        return True

    def transform_data(self, raw_data: List[Dict]) -> List[Dict]:
        """Transform: Nettoyer et enrichir les donn√©es"""
        logger.info("üîÑ Transformation des donn√©es")

        transformed = []

        for record in raw_data:
            try:
                # Valider
                if not self.validate_record(record):
                    self.stats["errors"] += 1
                    continue

                # Transformer
                transformed_record = {
                    "user_id": record.get('id'),
                    "name": record.get('name', '').strip(),
                    "email": record.get('email', '').lower(),
                    "phone": record.get('phone', '').strip(),
                    "address": {
                        "street": record.get('address', {}).get('street', ''),
                        "city": record.get('address', {}).get('city', ''),
                        "zipcode": record.get('address', {}).get('zipcode', ''),
                        "geo": {
                            "lat": float(record.get('address', {}).get('geo', {}).get('lat', 0)),
                            "lng": float(record.get('address', {}).get('geo', {}).get('lng', 0))
                        }
                    },
                    "company": {
                        "name": record.get('company', {}).get('name', ''),
                        "catchPhrase": record.get('company', {}).get('catchPhrase', '')
                    },
                    "metadata": {
                        "source": "api",
                        "imported_at": datetime.utcnow(),
                        "version": "1.0"
                    },
                    "status": "active"
                }

                transformed.append(transformed_record)
                self.stats["transformed"] += 1

            except Exception as e:
                logger.error(f"‚ùå Erreur transformation: {e} - Record: {record.get('id')}")
                self.stats["errors"] += 1

        logger.info(f"‚úÖ {self.stats['transformed']} enregistrements transform√©s")
        return transformed

    def load_to_mongodb(self, data: List[Dict], collection_name: str):
        """Load: Charger les donn√©es dans MongoDB"""
        logger.info(f"üíæ Chargement dans {collection_name}")

        if not data:
            logger.warning("‚ö†Ô∏è Aucune donn√©e √† charger")
            return

        collection = self.db[collection_name]

        try:
            # Bulk insert avec gestion d'erreurs
            result = collection.insert_many(data, ordered=False)
            self.stats["loaded"] = len(result.inserted_ids)
            logger.info(f"‚úÖ {self.stats['loaded']} documents ins√©r√©s")

            # Cr√©er des index
            collection.create_index([("email", 1)], unique=True, background=True)
            collection.create_index([("user_id", 1)], unique=True, background=True)
            collection.create_index([("address.city", 1)], background=True)
            logger.info("‚úÖ Index cr√©√©s")

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement: {e}")
            self.stats["errors"] += 1
            raise

    def generate_analytics(self, collection_name: str) -> Dict:
        """G√©n√©rer des analytics sur les donn√©es charg√©es"""
        logger.info("üìä G√©n√©ration des analytics")

        collection = self.db[collection_name]

        analytics = {}

        try:
            # 1. Statistiques g√©n√©rales
            analytics['total_users'] = collection.count_documents({})
            analytics['active_users'] = collection.count_documents({"status": "active"})

            # 2. Top 5 villes
            pipeline_cities = [
                {
                    "$group": {
                        "_id": "$address.city",
                        "count": {"$sum": 1}
                    }
                },
                {"$sort": {"count": -1}},
                {"$limit": 5}
            ]
            analytics['top_cities'] = list(collection.aggregate(pipeline_cities))

            # 3. Utilisateurs par domaine email
            pipeline_domains = [
                {
                    "$project": {
                        "domain": {
                            "$arrayElemAt": [
                                {"$split": ["$email", "@"]},
                                1
                            ]
                        }
                    }
                },
                {
                    "$group": {
                        "_id": "$domain",
                        "count": {"$sum": 1}
                    }
                },
                {"$sort": {"count": -1}}
            ]
            analytics['domains'] = list(collection.aggregate(pipeline_domains))

            logger.info("‚úÖ Analytics g√©n√©r√©s")
            return analytics

        except Exception as e:
            logger.error(f"‚ùå Erreur analytics: {e}")
            return {}

    def export_report(self, analytics: Dict, filename: str = "etl_report.json"):
        """Exporter un rapport JSON"""
        report = {
            "pipeline_run": {
                "timestamp": datetime.utcnow().isoformat(),
                "status": "success" if self.stats["errors"] == 0 else "completed_with_errors"
            },
            "statistics": self.stats,
            "analytics": analytics
        }

        with open(filename, 'w') as f:
            json.dump(report, f, indent=2, default=str)

        logger.info(f"üìÑ Rapport export√©: {filename}")

    def run_pipeline(self, api_url: str, collection_name: str):
        """Ex√©cuter le pipeline complet"""
        logger.info("=" * 50)
        logger.info("üöÄ D√âMARRAGE DU PIPELINE ETL")
        logger.info("=" * 50)

        try:
            # Connect
            self.connect()

            # Extract
            raw_data = self.extract_from_api(api_url)

            # Transform
            transformed_data = self.transform_data(raw_data)

            # Load
            self.load_to_mongodb(transformed_data, collection_name)

            # Analyze
            analytics = self.generate_analytics(collection_name)

            # Report
            self.export_report(analytics)

            # Summary
            logger.info("=" * 50)
            logger.info("‚úÖ PIPELINE ETL TERMIN√â AVEC SUCC√àS")
            logger.info(f"üìä Extraits: {self.stats['extracted']}")
            logger.info(f"üîÑ Transform√©s: {self.stats['transformed']}")
            logger.info(f"üíæ Charg√©s: {self.stats['loaded']}")
            logger.info(f"‚ùå Erreurs: {self.stats['errors']}")
            logger.info("=" * 50)

        except Exception as e:
            logger.error(f"‚ùå ERREUR CRITIQUE DU PIPELINE: {e}")
            raise

        finally:
            self.disconnect()


# Utilisation
if __name__ == "__main__":
    # Configuration
    MONGO_URI = "mongodb://admin:SecurePass123@localhost:27017/"
    DATABASE = "dataeng"
    API_URL = "https://jsonplaceholder.typicode.com/users"
    COLLECTION = "etl_users"

    # Ex√©cuter le pipeline
    pipeline = MongoDBETLPipeline(MONGO_URI, DATABASE)
    pipeline.run_pipeline(API_URL, COLLECTION)
```

**Ex√©cuter :**

```bash
python etl_pipeline.py
```

**Crit√®res de validation :**
- ‚úÖ Pipeline ETL complet fonctionnel
- ‚úÖ Extract, Transform, Load impl√©ment√©s
- ‚úÖ Validation des donn√©es
- ‚úÖ Gestion d'erreurs compl√®te
- ‚úÖ Logging d√©taill√©
- ‚úÖ Index cr√©√©s automatiquement
- ‚úÖ Analytics g√©n√©r√©s
- ‚úÖ Rapport JSON export√©

---

### T√¢che 5.2 : V√©rifier et analyser les r√©sultats

**Instructions :**

```bash
# 1. V√©rifier les logs
cat etl_pipeline.log

# 2. Voir le rapport JSON
cat etl_report.json

# 3. V√©rifier dans MongoDB
docker exec -it mongodb_dev mongosh -u admin -p SecurePass123

# Dans le shell MongoDB :
use dataeng
db.etl_users.countDocuments()
db.etl_users.findOne()
db.etl_users.getIndexes()
exit
```

**Crit√®res de validation :**
- ‚úÖ Log fichier cr√©√© avec toutes les op√©rations
- ‚úÖ Rapport JSON contenant stats et analytics
- ‚úÖ Donn√©es dans MongoDB
- ‚úÖ Index cr√©√©s

---

## üì§ Livrables

√Ä la fin du brief, vous devez avoir :

### 1. Infrastructure MongoDB :
- ‚úÖ MongoDB running avec Docker
- ‚úÖ Mongo Express accessible
- ‚úÖ Connexion Python fonctionnelle

### 2. Collections cr√©√©es :
- ‚úÖ `users` (donn√©es initiales)
- ‚úÖ `sales` (100+ ventes g√©n√©r√©es)
- ‚úÖ `etl_users` (donn√©es import√©es via ETL)

### 3. Scripts Python (10+ fichiers) :
- ‚úÖ test_connection.py
- ‚úÖ insert_data.py
- ‚úÖ queries.py
- ‚úÖ updates.py
- ‚úÖ deletes.py
- ‚úÖ aggregations.py
- ‚úÖ advanced_aggregations.py
- ‚úÖ export_analytics.py
- ‚úÖ performance_analysis.py
- ‚úÖ optimize_aggregations.py
- ‚úÖ etl_pipeline.py

### 4. Fichiers de donn√©es :
- ‚úÖ sales_export.csv
- ‚úÖ sales_analytics.csv
- ‚úÖ products_analytics.csv
- ‚úÖ etl_report.json
- ‚úÖ etl_pipeline.log

### 5. Documentation :
- ‚úÖ README.md expliquant le projet
- ‚úÖ Commentaires dans le code
- ‚úÖ Logs d√©taill√©s

---

## ‚úÖ Crit√®res d'√âvaluation

| Crit√®re | Points |
|---------|--------|
| Installation et configuration | 10 |
| Op√©rations CRUD compl√®tes | 15 |
| Agr√©gations simples et complexes | 20 |
| Optimisation et index | 15 |
| Pipeline ETL complet | 25 |
| Qualit√© du code et logs | 10 |
| Documentation | 5 |

**Total : 100 points**

**Bonus (+10 points) :**
- Change Streams impl√©ment√©s
- Transactions ACID utilis√©es
- Dashboard de visualisation cr√©√©
- Tests unitaires ajout√©s

---

## üí° Conseils

### Performance
- üîç **Index strat√©giques** : Indexez les champs de vos requ√™tes fr√©quentes
- üìä **$match t√¥t** : Placez $match au d√©but des pipelines
- üíæ **Projection** : Limitez les champs r√©cup√©r√©s
- üöÄ **allowDiskUse** : Activez pour les grandes agr√©gations

### Mod√©lisation
- üóÇÔ∏è **Embed vs Reference** : Embed pour one-to-few, reference pour one-to-many
- üìê **Sch√©ma flexible** : Profitez de la flexibilit√© mais documentez
- üéØ **Design par usage** : Mod√©lisez selon vos patterns d'acc√®s

### Production
- üîí **S√©curit√©** : Utilisez des credentials s√©curis√©s
- üìù **Logging** : Loggez tout pour le debugging
- ‚ö†Ô∏è **Gestion d'erreurs** : Try-except sur toutes les op√©rations
- üíæ **Backups** : Mettez en place des sauvegardes r√©guli√®res

---

## üÜò Troubleshooting

### MongoDB ne d√©marre pas
```bash
# V√©rifier les logs
docker-compose logs mongodb

# Red√©marrer
docker-compose restart mongodb

# Recr√©er les conteneurs
docker-compose down -v
docker-compose up -d
```

### Erreur de connexion Python
```python
# V√©rifier la connexion
from pymongo import MongoClient
client = MongoClient('mongodb://localhost:27017/', serverSelectionTimeoutMS=5000)
try:
    client.admin.command('ping')
    print("‚úÖ Connect√©")
except Exception as e:
    print(f"‚ùå Erreur: {e}")
```

### Performance lente
```javascript
// Analyser une requ√™te
db.collection.find({query}).explain("executionStats")

// V√©rifier les index
db.collection.getIndexes()

// Cr√©er un index
db.collection.createIndex({field: 1})
```

---

## üìö Ressources

### Documentation
- [MongoDB Manual](https://www.mongodb.com/docs/manual/)
- [PyMongo Documentation](https://pymongo.readthedocs.io/)
- [Aggregation Pipeline](https://www.mongodb.com/docs/manual/aggregation/)

### Tutorials
- [MongoDB University](https://university.mongodb.com/) - Cours gratuits
- [MongoDB Developer Hub](https://www.mongodb.com/developer/)

### Tools
- [MongoDB Compass](https://www.mongodb.com/products/compass) - GUI officielle
- [Studio 3T](https://studio3t.com/) - IDE MongoDB avanc√©
- [NoSQLBooster](https://nosqlbooster.com/) - Client MongoDB

---

**Bon courage ! üöÄ**

*MongoDB : La base NoSQL pour vos projets Data Engineering modernes !*
