{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Databricks notebook source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Exercice 03 : Fonctions de Fenetre (Window Functions)\n",
        "\n",
        "## Objectifs pedagogiques\n",
        "\n",
        "A la fin de cet exercice, vous serez capable de :\n",
        "- Comprendre le concept de fenetre (window)\n",
        "- Utiliser les fonctions de classement (rank, dense_rank, row_number)\n",
        "- Calculer des sommes cumulatives et moyennes mobiles\n",
        "- Utiliser lag() et lead() pour comparer avec les lignes precedentes/suivantes\n",
        "- Partitionner les donnees pour des calculs par groupe\n",
        "\n",
        "## Duree estimee : 75 minutes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 1 : Concepts theoriques\n",
        "\n",
        "### Qu'est-ce qu'une Window Function ?\n",
        "\n",
        "Les fonctions de fenetre effectuent des calculs sur un ensemble de lignes\n",
        "qui sont liees a la ligne courante, SANS regrouper les lignes (contrairement a GROUP BY).\n",
        "\n",
        "**Difference cle avec GROUP BY** :\n",
        "- GROUP BY : Reduit le nombre de lignes (une ligne par groupe)\n",
        "- Window Function : Conserve toutes les lignes (ajoute des colonnes calculees)\n",
        "\n",
        "### Structure d'une Window\n",
        "\n",
        "Une fenetre se definit par :\n",
        "1. **PARTITION BY** : Diviser les donnees en groupes\n",
        "2. **ORDER BY** : Trier les lignes dans chaque partition\n",
        "3. **FRAME** : Definir la plage de lignes a considerer (optionnel)\n",
        "\n",
        "### Categories de fonctions :\n",
        "\n",
        "1. **Ranking** : row_number(), rank(), dense_rank(), percent_rank()\n",
        "2. **Analytiques** : lag(), lead(), first(), last()\n",
        "3. **Agregats** : sum(), avg(), min(), max(), count()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 2 : Preparation des donnees\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"PREPARATION : Creer un dataset enrichi\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from pyspark.sql.functions import col, when, length\n",
        "\n",
        "# Charger et enrichir les donnees\n",
        "df_gares = spark.table(\"gares_silver\")\n",
        "\n",
        "# Creer un dataset avec plus d'informations pour les exemples\n",
        "df_enrichi = df_gares \\\n",
        "    .withColumn(\n",
        "        \"region\",\n",
        "        when(col(\"code_departement\").isin(\"75\", \"77\", \"78\", \"91\", \"92\", \"93\", \"94\", \"95\"), \"Ile-de-France\")\n",
        "        .when(col(\"code_departement\").isin(\"69\", \"01\", \"42\", \"38\", \"73\", \"74\"), \"Auvergne-Rhone-Alpes\")\n",
        "        .when(col(\"code_departement\").isin(\"13\", \"83\", \"84\", \"04\", \"05\", \"06\"), \"PACA\")\n",
        "        .when(col(\"code_departement\").isin(\"59\", \"62\", \"02\", \"80\", \"60\"), \"Hauts-de-France\")\n",
        "        .when(col(\"code_departement\").isin(\"33\", \"40\", \"47\", \"64\"), \"Nouvelle-Aquitaine\")\n",
        "        .otherwise(\"Autre\")\n",
        "    ) \\\n",
        "    .withColumn(\"longueur_nom\", length(col(\"nom\")))\n",
        "\n",
        "print(f\"Dataset enrichi : {df_enrichi.count()} lignes\")\n",
        "df_enrichi.select(\"nom\", \"code_departement\", \"region\", \"segment_clean\").show(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 3 : Fonctions de classement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"EXERCICE 3.1 : ROW_NUMBER, RANK et DENSE_RANK\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, rank, dense_rank, col\n",
        "\n",
        "# Definir une fenetre : partitionner par region, trier par nom\n",
        "window_region = Window.partitionBy(\"region\").orderBy(\"nom\")\n",
        "\n",
        "# Appliquer les trois fonctions de classement\n",
        "df_classement = df_enrichi \\\n",
        "    .filter(col(\"region\").isin(\"Ile-de-France\", \"PACA\")) \\\n",
        "    .withColumn(\"row_number\", row_number().over(window_region)) \\\n",
        "    .withColumn(\"rank\", rank().over(window_region)) \\\n",
        "    .withColumn(\"dense_rank\", dense_rank().over(window_region)) \\\n",
        "    .select(\"region\", \"nom\", \"row_number\", \"rank\", \"dense_rank\")\n",
        "\n",
        "print(\"Comparaison des fonctions de classement :\")\n",
        "df_classement.orderBy(\"region\", \"row_number\").show(20)\n",
        "\n",
        "print(\"\"\"\n",
        "DIFFERENCES :\n",
        "- row_number() : Numerotation continue (1, 2, 3, 4...)\n",
        "- rank() : Saute des rangs en cas d'egalite (1, 2, 2, 4...)\n",
        "- dense_rank() : Pas de saut (1, 2, 2, 3...)\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## EXERCICE PRATIQUE 3.2\n",
        "\n",
        "Pour chaque departement, classez les gares par longueur de nom (decroissant) :\n",
        "1. Utilisez row_number()\n",
        "2. Affichez uniquement : code_departement, nom, longueur_nom, rang\n",
        "3. Filtrez pour garder les 3 premieres de chaque departement\n",
        "4. Limitez aux departements 75, 69, 13\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# A COMPLETER\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, col\n",
        "\n",
        "# Definir la fenetre\n",
        "window_dept = Window.partitionBy(\"code_departement\").orderBy(col(\"longueur_nom\").desc())\n",
        "\n",
        "# Appliquer row_number et filtrer\n",
        "df_top3_noms_longs = df_enrichi \\\n",
        "    .filter(col(\"code_departement\").isin(\"75\", \"69\", \"13\")) \\\n",
        "    .withColumn(\"rang\", row_number().over(window_dept)) \\\n",
        "    .filter(col(\"rang\") <= 3) \\\n",
        "    .select(\"code_departement\", \"nom\", \"longueur_nom\", \"rang\") \\\n",
        "    .orderBy(\"code_departement\", \"rang\")\n",
        "\n",
        "print(\"Top 3 des gares avec les noms les plus longs par departement :\")\n",
        "df_top3_noms_longs.show(20, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 4 : LAG et LEAD (valeurs precedentes/suivantes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"EXERCICE 3.3 : LAG et LEAD\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from pyspark.sql.functions import lag, lead, col\n",
        "\n",
        "# Fenetre : trier les gares d'Ile-de-France par nom\n",
        "window_idf = Window.partitionBy(\"region\").orderBy(\"nom\")\n",
        "\n",
        "df_lag_lead = df_enrichi \\\n",
        "    .filter(col(\"region\") == \"Ile-de-France\") \\\n",
        "    .withColumn(\"gare_precedente\", lag(\"nom\", 1).over(window_idf)) \\\n",
        "    .withColumn(\"gare_suivante\", lead(\"nom\", 1).over(window_idf)) \\\n",
        "    .select(\"nom\", \"gare_precedente\", \"gare_suivante\")\n",
        "\n",
        "print(\"LAG (precedent) et LEAD (suivant) :\")\n",
        "df_lag_lead.show(15, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## EXERCICE PRATIQUE 3.4\n",
        "\n",
        "Pour les gares du departement 75, triees par latitude (sud vers nord) :\n",
        "1. Affichez la gare precedente et suivante\n",
        "2. Calculez la difference de latitude avec la gare precedente\n",
        "3. Affichez : nom, latitude, gare_precedente, diff_latitude\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# A COMPLETER\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import lag, col, round\n",
        "\n",
        "# Fenetre : trier par latitude\n",
        "window_lat = Window.partitionBy(\"code_departement\").orderBy(\"latitude\")\n",
        "\n",
        "df_paris_lat = df_enrichi \\\n",
        "    .filter(col(\"code_departement\") == \"75\") \\\n",
        "    .withColumn(\"gare_precedente\", lag(\"nom\", 1).over(window_lat)) \\\n",
        "    .withColumn(\"lat_precedente\", lag(\"latitude\", 1).over(window_lat)) \\\n",
        "    .withColumn(\"diff_latitude\", round(col(\"latitude\") - col(\"lat_precedente\"), 6)) \\\n",
        "    .select(\"nom\", \"latitude\", \"gare_precedente\", \"diff_latitude\") \\\n",
        "    .orderBy(\"latitude\")\n",
        "\n",
        "print(\"Gares de Paris triees du sud au nord :\")\n",
        "df_paris_lat.show(20, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 5 : Agregations dans une fenetre\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"EXERCICE 3.5 : Somme cumulative (Running Total)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import sum, count, col\n",
        "\n",
        "# Compter les gares cumulees par region (ordre alphabetique)\n",
        "window_cumul = Window.partitionBy(\"region\").orderBy(\"nom\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "df_cumul = df_enrichi \\\n",
        "    .filter(col(\"region\").isin(\"Ile-de-France\", \"PACA\")) \\\n",
        "    .withColumn(\"numero\", row_number().over(Window.partitionBy(\"region\").orderBy(\"nom\"))) \\\n",
        "    .withColumn(\"cumul_gares\", count(\"*\").over(window_cumul)) \\\n",
        "    .select(\"region\", \"nom\", \"numero\", \"cumul_gares\")\n",
        "\n",
        "print(\"Cumul du nombre de gares par region :\")\n",
        "df_cumul.show(30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## EXERCICE PRATIQUE 3.6\n",
        "\n",
        "Pour chaque region, calculez :\n",
        "1. Le nombre cumule de gares (ordre alphabetique)\n",
        "2. Le pourcentage du total de la region\n",
        "3. Affichez : region, nom, cumul, pourcentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# A COMPLETER\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import count, col, round\n",
        "\n",
        "# Fenetre pour le cumul\n",
        "window_cumul = Window.partitionBy(\"region\").orderBy(\"nom\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "# Fenetre pour le total\n",
        "window_total = Window.partitionBy(\"region\")\n",
        "\n",
        "df_progression = df_enrichi \\\n",
        "    .filter(col(\"region\").isin(\"Ile-de-France\", \"PACA\", \"Hauts-de-France\")) \\\n",
        "    .withColumn(\"cumul\", count(\"*\").over(window_cumul)) \\\n",
        "    .withColumn(\"total\", count(\"*\").over(window_total)) \\\n",
        "    .withColumn(\"pourcentage\", round((col(\"cumul\") * 100.0 / col(\"total\")), 2)) \\\n",
        "    .select(\"region\", \"nom\", \"cumul\", \"total\", \"pourcentage\")\n",
        "\n",
        "print(\"Progression cumulee par region :\")\n",
        "df_progression.show(30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 6 : Moyenne mobile (Moving Average)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"EXERCICE 3.7 : Moyenne mobile\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import avg, col, round, row_number\n",
        "\n",
        "# Fenetre glissante : 2 lignes avant + ligne courante + 2 lignes apres\n",
        "window_mobile = Window.partitionBy(\"region\").orderBy(\"latitude\").rowsBetween(-2, 2)\n",
        "\n",
        "df_mobile = df_enrichi \\\n",
        "    .filter(col(\"region\") == \"Ile-de-France\") \\\n",
        "    .withColumn(\"lat_moyenne_mobile\", round(avg(\"latitude\").over(window_mobile), 6)) \\\n",
        "    .withColumn(\"lon_moyenne_mobile\", round(avg(\"longitude\").over(window_mobile), 6)) \\\n",
        "    .select(\"nom\", \"latitude\", \"lat_moyenne_mobile\", \"longitude\", \"lon_moyenne_mobile\") \\\n",
        "    .orderBy(\"latitude\")\n",
        "\n",
        "print(\"Moyenne mobile sur 5 gares (2 avant, courante, 2 apres) :\")\n",
        "df_mobile.show(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 7 : FIRST et LAST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"EXERCICE 3.8 : Premiere et derniere valeur de la fenetre\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from pyspark.sql.functions import first, last, col\n",
        "\n",
        "# Fenetre : toute la partition\n",
        "window_full = Window.partitionBy(\"region\").orderBy(\"nom\").rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
        "\n",
        "df_first_last = df_enrichi \\\n",
        "    .filter(col(\"region\").isin(\"Ile-de-France\", \"PACA\")) \\\n",
        "    .withColumn(\"premiere_gare_region\", first(\"nom\").over(window_full)) \\\n",
        "    .withColumn(\"derniere_gare_region\", last(\"nom\").over(window_full)) \\\n",
        "    .select(\"region\", \"nom\", \"premiere_gare_region\", \"derniere_gare_region\") \\\n",
        "    .distinct()\n",
        "\n",
        "print(\"Premiere et derniere gare de chaque region (ordre alphabetique) :\")\n",
        "df_first_last.show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## EXERCICE PRATIQUE 3.9 : Comparaison avec extremes\n",
        "\n",
        "Pour chaque region :\n",
        "1. Trouvez la gare la plus au nord (max latitude)\n",
        "2. Trouvez la gare la plus au sud (min latitude)\n",
        "3. Pour chaque gare, calculez sa distance (en latitude) par rapport au nord et au sud\n",
        "4. Limitez a la region Ile-de-France\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# A COMPLETER\n",
        "from pyspark.sql.functions import max, min, col, round\n",
        "\n",
        "# Fenetre pour toute la region\n",
        "window_region_full = Window.partitionBy(\"region\")\n",
        "\n",
        "df_distances = df_enrichi \\\n",
        "    .filter(col(\"region\") == \"Ile-de-France\") \\\n",
        "    .withColumn(\"lat_max_region\", max(\"latitude\").over(window_region_full)) \\\n",
        "    .withColumn(\"lat_min_region\", min(\"latitude\").over(window_region_full)) \\\n",
        "    .withColumn(\"distance_du_nord\", round(col(\"lat_max_region\") - col(\"latitude\"), 6)) \\\n",
        "    .withColumn(\"distance_du_sud\", round(col(\"latitude\") - col(\"lat_min_region\"), 6)) \\\n",
        "    .select(\"nom\", \"latitude\", \"lat_max_region\", \"lat_min_region\", \"distance_du_nord\", \"distance_du_sud\") \\\n",
        "    .orderBy(\"latitude\")\n",
        "\n",
        "print(\"Distance de chaque gare par rapport aux extremes de la region :\")\n",
        "df_distances.show(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 9 : Percentiles et quartiles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"EXERCICE 3.11 : Calcul de percentiles\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from pyspark.sql.functions import percent_rank, ntile, col, round\n",
        "\n",
        "# Fenetre : trier par longueur de nom\n",
        "window_percentile = Window.partitionBy(\"region\").orderBy(\"longueur_nom\")\n",
        "\n",
        "df_percentiles = df_enrichi \\\n",
        "    .filter(col(\"region\").isin(\"Ile-de-France\", \"PACA\")) \\\n",
        "    .withColumn(\"percent_rank\", round(percent_rank().over(window_percentile), 4)) \\\n",
        "    .withColumn(\"quartile\", ntile(4).over(window_percentile)) \\\n",
        "    .withColumn(\"decile\", ntile(10).over(window_percentile)) \\\n",
        "    .select(\"region\", \"nom\", \"longueur_nom\", \"percent_rank\", \"quartile\", \"decile\")\n",
        "\n",
        "print(\"Percentiles et quartiles basés sur la longueur du nom :\")\n",
        "df_percentiles.orderBy(\"region\", \"longueur_nom\").show(30)\n",
        "\n",
        "print(\"\"\"\n",
        "EXPLICATION :\n",
        "- percent_rank() : Position relative (0 a 1) dans la partition\n",
        "- ntile(4) : Divise en 4 quartiles egaux\n",
        "- ntile(10) : Divise en 10 deciles egaux\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## EXERCICE FINAL 3.12 : Analyse complete avec Window Functions\n",
        "\n",
        "Creez une analyse qui, pour chaque region :\n",
        "\n",
        "1. Classe les gares par latitude (du sud au nord)\n",
        "2. Calcule la latitude moyenne mobile sur 3 gares (1 avant, courante, 1 apres)\n",
        "3. Indique le nom de la gare precedente et suivante\n",
        "4. Calcule le rang dans la region\n",
        "5. Indique dans quel quartile se trouve la gare (ntile)\n",
        "6. Limite aux regions : Ile-de-France, PACA, Hauts-de-France\n",
        "7. Sauvegarde le resultat dans une table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# A COMPLETER - SOLUTION PROPOSEE\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, avg, lag, lead, ntile, col, round\n",
        "\n",
        "# Fenetres\n",
        "window_lat = Window.partitionBy(\"region\").orderBy(\"latitude\")\n",
        "window_mobile = Window.partitionBy(\"region\").orderBy(\"latitude\").rowsBetween(-1, 1)\n",
        "\n",
        "# Pipeline complete\n",
        "df_analyse_window = df_enrichi \\\n",
        "    .filter(col(\"region\").isin(\"Ile-de-France\", \"PACA\", \"Hauts-de-France\")) \\\n",
        "    .withColumn(\"rang_sud_nord\", row_number().over(window_lat)) \\\n",
        "    .withColumn(\"lat_moyenne_mobile\", round(avg(\"latitude\").over(window_mobile), 6)) \\\n",
        "    .withColumn(\"gare_precedente\", lag(\"nom\", 1).over(window_lat)) \\\n",
        "    .withColumn(\"gare_suivante\", lead(\"nom\", 1).over(window_lat)) \\\n",
        "    .withColumn(\"quartile\", ntile(4).over(window_lat)) \\\n",
        "    .select(\n",
        "        \"region\",\n",
        "        \"nom\",\n",
        "        \"latitude\",\n",
        "        \"rang_sud_nord\",\n",
        "        \"lat_moyenne_mobile\",\n",
        "        \"gare_precedente\",\n",
        "        \"gare_suivante\",\n",
        "        \"quartile\"\n",
        "    ) \\\n",
        "    .orderBy(\"region\", \"latitude\")\n",
        "\n",
        "print(\"Analyse complete avec window functions :\")\n",
        "df_analyse_window.show(30, truncate=False)\n",
        "\n",
        "# Sauvegarder\n",
        "df_analyse_window.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"analyse_window_gares\")\n",
        "print(\"\\nTable 'analyse_window_gares' creee !\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## PARTIE 10 : Window Functions en SQL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "%sql\n",
        "-- EXERCICE 3.13 : Meme analyse en SQL\n",
        "\n",
        "SELECT\n",
        "code_departement,\n",
        "nom,\n",
        "latitude,\n",
        "ROW_NUMBER() OVER (PARTITION BY code_departement ORDER BY latitude) as rang,\n",
        "RANK() OVER (PARTITION BY code_departement ORDER BY latitude) as rank,\n",
        "LAG(nom, 1) OVER (PARTITION BY code_departement ORDER BY latitude) as gare_precedente,\n",
        "LEAD(nom, 1) OVER (PARTITION BY code_departement ORDER BY latitude) as gare_suivante\n",
        "FROM gares_silver\n",
        "WHERE code_departement IN ('75', '69', '13')\n",
        "ORDER BY code_departement, latitude\n",
        "LIMIT 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "%sql\n",
        "-- Moyenne mobile en SQL\n",
        "SELECT\n",
        "code_departement,\n",
        "nom,\n",
        "latitude,\n",
        "ROUND(AVG(latitude) OVER (\n",
        "PARTITION BY code_departement\n",
        "ORDER BY latitude\n",
        "ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n",
        "), 6) as lat_moyenne_mobile\n",
        "FROM gares_silver\n",
        "WHERE code_departement = '75'\n",
        "ORDER BY latitude\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RESUME DES CONCEPTS APPRIS\n",
        "\n",
        "Dans cet exercice, vous avez appris :\n",
        "\n",
        "1. **Concept de fenetre** : PARTITION BY, ORDER BY, FRAME\n",
        "2. **Classement** : `row_number()`, `rank()`, `dense_rank()`, `percent_rank()`, `ntile()`\n",
        "3. **Acces aux lignes** : `lag()`, `lead()`, `first()`, `last()`\n",
        "4. **Agregations** : `sum()`, `avg()`, `count()`, `min()`, `max()` sur fenetre\n",
        "5. **Frames** : `rowsBetween()`, `rangeBetween()`\n",
        "6. **Cumuls** : Running totals, moyennes mobiles\n",
        "7. **Percentiles** : `percent_rank()`, `ntile()`\n",
        "8. **SQL** : Syntaxe `OVER (PARTITION BY... ORDER BY...)`\n",
        "\n",
        "## Cas d'usage pratiques\n",
        "\n",
        "- Classements et top N par categorie\n",
        "- Comparaisons avec periode precedente\n",
        "- Calcul de tendances (moyennes mobiles)\n",
        "- Detection d'anomalies (ecart par rapport a la moyenne)\n",
        "- Segmentation (quartiles, deciles)\n",
        "\n",
        "## Prochaine etape\n",
        "\n",
        "Passez a l'**Exercice 04 : Delta Lake avance** pour apprendre :\n",
        "- Time Travel (voyage dans le temps)\n",
        "- MERGE (upserts)\n",
        "- Change Data Capture (CDC)\n",
        "- Optimisations Delta (OPTIMIZE, Z-ORDER, VACUUM)\n"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookName": "Exercice_03_Window_Functions",
      "widgets": {}
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
