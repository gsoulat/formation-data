<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Partie 2 : Architecture HDFS - Formation Hadoop</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />

    <link rel="stylesheet" href="../assets/styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ’¾ Partie 2 : Architecture HDFS</h1>
            <p class="subtitle">Le systÃ¨me de fichiers distribuÃ© au cÅ“ur de Hadoop</p>
            <div class="duration">â±ï¸ DurÃ©e : 2h</div>
        </header>

        <nav class="nav-menu">
            <ul>
                <li><a href="../index.html">ğŸ  Accueil</a></li>
                <li><a href="partie1.html">â† Partie 1</a></li>
                <li><a href="partie2.html" class="active">Partie 2</a></li>
                <li><a href="partie3.html">Partie 3 â†’</a></li>
            </ul>
        </nav>

        <div class="content">
            <div class="objectives">
                <h2>ğŸ¯ Objectifs d'Apprentissage</h2>
                <ul>
                    <li>Comprendre l'architecture master/slave de HDFS</li>
                    <li>MaÃ®triser les concepts de NameNode et DataNode</li>
                    <li>ApprÃ©hender la rÃ©plication et la tolÃ©rance aux pannes</li>
                    <li>Utiliser les commandes HDFS essentielles</li>
                </ul>
            </div>

            <section class="section">
                <h2>ğŸ“š 1. Qu'est-ce que HDFS ?</h2>

                <p>
                    <strong>HDFS</strong> (Hadoop Distributed File System) est le systÃ¨me de fichiers distribuÃ© de Hadoop.
                    C'est un systÃ¨me conÃ§u pour stocker de trÃ¨s grandes quantitÃ©s de donnÃ©es sur plusieurs machines tout en
                    offrant une tolÃ©rance aux pannes et un dÃ©bit Ã©levÃ©.
                </p>

                <h3>Principes de Conception</h3>
                <div class="grid">
                    <div class="grid-item">
                        <h4>ğŸ’ª TolÃ©rance aux Pannes</h4>
                        <p>Les pannes matÃ©rielles sont la norme, pas l'exception. HDFS dÃ©tecte et rÃ©cupÃ¨re automatiquement.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ“ˆ ScalabilitÃ©</h4>
                        <p>ConÃ§u pour s'adapter Ã  des centaines ou milliers de nÅ“uds dans un cluster.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ“Š Gros Fichiers</h4>
                        <p>OptimisÃ© pour stocker des fichiers de plusieurs gigaoctets Ã  tÃ©raoctets.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ”„ AccÃ¨s Streaming</h4>
                        <p>ConÃ§u pour des lectures sÃ©quentielles rapides plutÃ´t que des accÃ¨s alÃ©atoires.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ’» MatÃ©riel Standard</h4>
                        <p>Fonctionne sur du matÃ©riel commodity (bon marchÃ©), pas de serveurs spÃ©cialisÃ©s requis.</p>
                    </div>
                    <div class="grid-item">
                        <h4>âœï¸ Write Once, Read Many</h4>
                        <p>Les fichiers sont Ã©crits une fois et lus plusieurs fois. Pas de modifications en place.</p>
                    </div>
                </div>

                <div class="alert alert-info">
                    <h4>Analogie</h4>
                    <p>
                        Imaginez une bibliothÃ¨que oÃ¹ les livres (donnÃ©es) sont rÃ©partis dans plusieurs bÃ¢timents (DataNodes).
                        Il y a un catalogue central (NameNode) qui sait exactement dans quel bÃ¢timent se trouve chaque livre.
                        Chaque livre existe en plusieurs exemplaires dans diffÃ©rents bÃ¢timents pour Ã©viter la perte.
                    </p>
                </div>
            </section>

            <section class="section">
                <h2>ğŸ—ï¸ 2. Architecture de HDFS</h2>

                <h3>Vue d'Ensemble</h3>
                <p>HDFS suit une architecture <strong>Master/Slave</strong> (ou Master/Worker) :</p>

                <div class="workflow-diagram">
                    <pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CLIENT                                â”‚
â”‚                    (Application Hadoop)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                          â”‚
         â”‚ MÃ©tadonnÃ©es                             â”‚ DonnÃ©es
         â†“                                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     NAMENODE       â”‚ â† Heartbeat &     â”‚     DATANODES        â”‚
â”‚   (Master/MaÃ®tre)  â”‚   Block Reports â†’ â”‚   (Slaves/Workers)   â”‚
â”‚                    â”‚                    â”‚                      â”‚
â”‚ - MÃ©tadonnÃ©es      â”‚                    â”‚  DataNode 1          â”‚
â”‚ - Arborescence     â”‚                    â”‚  DataNode 2          â”‚
â”‚ - Localisation     â”‚                    â”‚  DataNode 3          â”‚
â”‚   des blocs        â”‚                    â”‚  DataNode N          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SECONDARY NAMENODE â”‚
â”‚   (Checkpoint)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                </div>

                <h3>Composants Principaux</h3>

                <h4>ğŸ¯ NameNode (Master)</h4>
                <div class="card">
                    <p>Le NameNode est le <strong>maÃ®tre</strong> du cluster HDFS. Il gÃ¨re :</p>
                    <ul>
                        <li><strong>MÃ©tadonnÃ©es</strong> : Structure de l'arborescence des fichiers et rÃ©pertoires</li>
                        <li><strong>Namespace</strong> : Noms de fichiers, permissions, propriÃ©taires</li>
                        <li><strong>Mapping des blocs</strong> : Quelle partie de fichier est stockÃ©e oÃ¹</li>
                        <li><strong>Heartbeats</strong> : Surveillance de l'Ã©tat des DataNodes</li>
                        <li><strong>RÃ©plication</strong> : DÃ©cisions sur oÃ¹ rÃ©pliquer les blocs</li>
                    </ul>

                    <div class="alert alert-danger">
                        <h4>Point de DÃ©faillance Unique (SPOF)</h4>
                        <p>
                            Le NameNode est critique ! Si le NameNode tombe en panne, tout le cluster devient inaccessible.
                            Solution : <strong>High Availability (HA)</strong> avec un NameNode de secours.
                        </p>
                    </div>
                </div>

                <h4>ğŸ’¾ DataNodes (Slaves)</h4>
                <div class="card">
                    <p>Les DataNodes sont les <strong>esclaves/workers</strong> qui :</p>
                    <ul>
                        <li>Stockent physiquement les donnÃ©es sous forme de blocs</li>
                        <li>Servent les requÃªtes de lecture et d'Ã©criture des clients</li>
                        <li>Envoient des heartbeats au NameNode toutes les 3 secondes</li>
                        <li>Envoient des block reports (liste de blocs stockÃ©s) rÃ©guliÃ¨rement</li>
                        <li>ExÃ©cutent les instructions du NameNode (rÃ©plication, suppression)</li>
                    </ul>
                </div>

                <h4>ğŸ”„ Secondary NameNode</h4>
                <div class="card">
                    <p><strong>Attention :</strong> Ce n'est PAS un NameNode de backup !</p>
                    <p>Le Secondary NameNode :</p>
                    <ul>
                        <li>Fusionne pÃ©riodiquement les fichiers FSImage et EditLog</li>
                        <li>CrÃ©e des checkpoints pour accÃ©lÃ©rer le redÃ©marrage du NameNode</li>
                        <li>RÃ©duit la charge du NameNode principal</li>
                    </ul>
                    <p><em>Note : En production, on utilise plutÃ´t la configuration High Availability avec un Standby NameNode.</em></p>
                </div>
            </section>

            <section class="section">
                <h2>ğŸ§© 3. Blocs et RÃ©plication</h2>

                <h3>Concept de Blocs</h3>
                <p>
                    Dans HDFS, les fichiers sont dÃ©coupÃ©s en <strong>blocs</strong> de taille fixe.
                </p>

                <table>
                    <thead>
                        <tr>
                            <th>Version Hadoop</th>
                            <th>Taille de Bloc par DÃ©faut</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Hadoop 1.x</td>
                            <td>64 MB</td>
                        </tr>
                        <tr>
                            <td>Hadoop 2.x et 3.x</td>
                            <td>128 MB</td>
                        </tr>
                    </tbody>
                </table>

                <div class="alert alert-info">
                    <h4>Exemple</h4>
                    <p>
                        Un fichier de 300 MB sera dÃ©coupÃ© en :
                    </p>
                    <ul>
                        <li>Bloc 1 : 128 MB</li>
                        <li>Bloc 2 : 128 MB</li>
                        <li>Bloc 3 : 44 MB (reste du fichier)</li>
                    </ul>
                </div>

                <h3>Pourquoi des Blocs Aussi Gros ?</h3>
                <div class="grid">
                    <div class="grid-item">
                        <h4>ğŸ“‰ Minimiser les MÃ©tadonnÃ©es</h4>
                        <p>Moins de blocs = moins de mÃ©tadonnÃ©es Ã  gÃ©rer dans le NameNode</p>
                    </div>
                    <div class="grid-item">
                        <h4>âš¡ Optimiser le DÃ©bit</h4>
                        <p>Transferts sÃ©quentiels longs = meilleur dÃ©bit rÃ©seau et disque</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ” RÃ©duire le Seek Time</h4>
                        <p>Moins de dÃ©placements de la tÃªte de lecture sur le disque</p>
                    </div>
                </div>

                <h3>RÃ©plication des Blocs</h3>
                <p>
                    Chaque bloc est <strong>rÃ©pliquÃ©</strong> sur plusieurs DataNodes pour assurer la tolÃ©rance aux pannes.
                    Le facteur de rÃ©plication par dÃ©faut est <strong>3</strong>.
                </p>

                <div class="workflow-diagram">
                    <pre>
Fichier original (300 MB)
         â†“
DÃ©coupage en blocs
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bloc A â”‚ Bloc B â”‚ Bloc C â”‚
â”‚ 128 MB â”‚ 128 MB â”‚ 44 MB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
RÃ©plication (facteur 3)

Rack 1              Rack 2              Rack 3
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataNode 1  â”‚    â”‚ DataNode 3  â”‚    â”‚ DataNode 5  â”‚
â”‚ A, B        â”‚    â”‚ A, C        â”‚    â”‚ B, C        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DataNode 2  â”‚    â”‚ DataNode 4  â”‚    â”‚ DataNode 6  â”‚
â”‚ B, C        â”‚    â”‚ A, B        â”‚    â”‚ A           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                </div>

                <h3>StratÃ©gie de Placement des RÃ©pliques</h3>
                <div class="key-points">
                    <h3>ğŸ¯ Politique par DÃ©faut (Rack Awareness)</h3>
                    <ul>
                        <li><strong>RÃ©plique 1</strong> : Sur le nÅ“ud local (ou alÃ©atoire si Ã©criture depuis l'extÃ©rieur)</li>
                        <li><strong>RÃ©plique 2</strong> : Sur un nÅ“ud d'un rack diffÃ©rent</li>
                        <li><strong>RÃ©plique 3</strong> : Sur un autre nÅ“ud du mÃªme rack que la rÃ©plique 2</li>
                    </ul>
                    <p>
                        <strong>Avantages :</strong> Balance entre fiabilitÃ© (tolÃ©rance aux pannes de rack) et
                        performance rÃ©seau (2 rÃ©pliques sur le mÃªme rack = moins de bande passante inter-rack).
                    </p>
                </div>
            </section>

            <section class="section">
                <h2>âš™ï¸ 4. Lecture et Ã‰criture dans HDFS</h2>

                <h3>Processus de Lecture</h3>
                <div class="workflow-diagram">
                    <pre>
1. Client demande au NameNode les mÃ©tadonnÃ©es du fichier
   â†“
2. NameNode retourne la liste des blocs et leur localisation
   â†“
3. Client contacte directement les DataNodes pour lire les blocs
   â†“
4. Client reÃ§oit les donnÃ©es et les assemble
                    </pre>
                </div>

                <div class="alert alert-success">
                    <h4>Optimisation</h4>
                    <p>
                        Le client lit toujours depuis le DataNode le plus proche (mÃªme rack, puis mÃªme datacenter).
                        Cela minimise la latence et la consommation de bande passante rÃ©seau.
                    </p>
                </div>

                <h3>Processus d'Ã‰criture</h3>
                <div class="workflow-diagram">
                    <pre>
1. Client demande au NameNode de crÃ©er un nouveau fichier
   â†“
2. NameNode vÃ©rifie les permissions et crÃ©e l'entrÃ©e
   â†“
3. Client dÃ©coupe le fichier en blocs et demande les DataNodes cibles
   â†“
4. NameNode fournit une liste de DataNodes pour chaque bloc
   â†“
5. Client envoie le premier bloc au premier DataNode
   â†“
6. Le DataNode rÃ©plique automatiquement vers les autres DataNodes (pipeline)
   â†“
7. Une fois tous les blocs Ã©crits et rÃ©pliquÃ©s, le fichier est "fermÃ©"
                    </pre>
                </div>

                <h4>Pipeline de RÃ©plication</h4>
                <div class="workflow-diagram">
                    <pre>
Client  â†’  DataNode 1  â†’  DataNode 2  â†’  DataNode 3
                â†“              â†“              â†“
              ACK 1  â†  ACK 2  â†  ACK 3
                    </pre>
                </div>
                <p>
                    Les donnÃ©es sont envoyÃ©es en pipeline : pendant que DataNode 1 reÃ§oit le bloc, il commence
                    dÃ©jÃ  Ã  l'envoyer Ã  DataNode 2, qui l'envoie Ã  DataNode 3. C'est trÃ¨s efficace !
                </p>
            </section>

            <section class="section">
                <h2>ğŸ’» 5. Commandes HDFS Essentielles</h2>

                <p>HDFS propose des commandes similaires aux commandes Unix pour manipuler les fichiers.</p>

                <h3>Format GÃ©nÃ©ral</h3>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash">hdfs dfs -&lt;commande&gt; &lt;arguments&gt;
# ou
hadoop fs -&lt;commande&gt; &lt;arguments&gt;</code></pre>
                </div>

                <h3>Commandes de Base</h3>
                <table class="command-table">
                    <thead>
                        <tr>
                            <th>Commande</th>
                            <th>Description</th>
                            <th>Exemple</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ls</td>
                            <td>Lister les fichiers et rÃ©pertoires</td>
                            <td><code>hdfs dfs -ls /user/data</code></td>
                        </tr>
                        <tr>
                            <td>mkdir</td>
                            <td>CrÃ©er un rÃ©pertoire</td>
                            <td><code>hdfs dfs -mkdir /user/mydir</code></td>
                        </tr>
                        <tr>
                            <td>put</td>
                            <td>Copier un fichier local vers HDFS</td>
                            <td><code>hdfs dfs -put data.txt /user/data/</code></td>
                        </tr>
                        <tr>
                            <td>get</td>
                            <td>Copier un fichier HDFS vers local</td>
                            <td><code>hdfs dfs -get /user/data/result.txt .</code></td>
                        </tr>
                        <tr>
                            <td>cat</td>
                            <td>Afficher le contenu d'un fichier</td>
                            <td><code>hdfs dfs -cat /user/data/log.txt</code></td>
                        </tr>
                        <tr>
                            <td>rm</td>
                            <td>Supprimer un fichier</td>
                            <td><code>hdfs dfs -rm /user/data/old.txt</code></td>
                        </tr>
                        <tr>
                            <td>rm -r</td>
                            <td>Supprimer un rÃ©pertoire</td>
                            <td><code>hdfs dfs -rm -r /user/data/olddir</code></td>
                        </tr>
                        <tr>
                            <td>cp</td>
                            <td>Copier dans HDFS</td>
                            <td><code>hdfs dfs -cp /src/file.txt /dest/</code></td>
                        </tr>
                        <tr>
                            <td>mv</td>
                            <td>DÃ©placer/renommer dans HDFS</td>
                            <td><code>hdfs dfs -mv /old/path /new/path</code></td>
                        </tr>
                        <tr>
                            <td>du</td>
                            <td>Taille des fichiers/rÃ©pertoires</td>
                            <td><code>hdfs dfs -du -h /user/data</code></td>
                        </tr>
                        <tr>
                            <td>df</td>
                            <td>Espace disque disponible</td>
                            <td><code>hdfs dfs -df -h</code></td>
                        </tr>
                    </tbody>
                </table>

                <h3>Commandes AvancÃ©es</h3>
                <table class="command-table">
                    <thead>
                        <tr>
                            <th>Commande</th>
                            <th>Description</th>
                            <th>Exemple</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>copyFromLocal</td>
                            <td>Copier local â†’ HDFS (idem put)</td>
                            <td><code>hdfs dfs -copyFromLocal data.txt /user/</code></td>
                        </tr>
                        <tr>
                            <td>copyToLocal</td>
                            <td>Copier HDFS â†’ local (idem get)</td>
                            <td><code>hdfs dfs -copyToLocal /user/data.txt .</code></td>
                        </tr>
                        <tr>
                            <td>getmerge</td>
                            <td>Fusionner plusieurs fichiers HDFS en un seul local</td>
                            <td><code>hdfs dfs -getmerge /user/logs/* output.log</code></td>
                        </tr>
                        <tr>
                            <td>tail</td>
                            <td>Afficher la fin d'un fichier</td>
                            <td><code>hdfs dfs -tail /user/logs/app.log</code></td>
                        </tr>
                        <tr>
                            <td>chmod</td>
                            <td>Changer les permissions</td>
                            <td><code>hdfs dfs -chmod 755 /user/data</code></td>
                        </tr>
                        <tr>
                            <td>chown</td>
                            <td>Changer le propriÃ©taire</td>
                            <td><code>hdfs dfs -chown user:group /user/data</code></td>
                        </tr>
                        <tr>
                            <td>setrep</td>
                            <td>Modifier le facteur de rÃ©plication</td>
                            <td><code>hdfs dfs -setrep -w 5 /user/important.txt</code></td>
                        </tr>
                        <tr>
                            <td>stat</td>
                            <td>Afficher les statistiques d'un fichier</td>
                            <td><code>hdfs dfs -stat %r /user/data.txt</code></td>
                        </tr>
                    </tbody>
                </table>

                <div class="exercise">
                    <h4>Exercice Pratique : Commandes HDFS</h4>
                    <p>Ã€ faire dans votre environnement Hadoop (vous le configurerez dans la Partie 6) :</p>
                    <ol>
                        <li>CrÃ©er un rÃ©pertoire <code>/user/votrenom/tp1</code></li>
                        <li>CrÃ©er un fichier local contenant "Hello Hadoop" et le copier dans HDFS</li>
                        <li>Lister le contenu du rÃ©pertoire dans HDFS</li>
                        <li>Afficher le contenu du fichier depuis HDFS</li>
                        <li>VÃ©rifier le facteur de rÃ©plication du fichier</li>
                        <li>Modifier le facteur de rÃ©plication Ã  5</li>
                        <li>Supprimer le fichier</li>
                    </ol>
                </div>
            </section>

            <section class="section">
                <h2>ğŸ›¡ï¸ 6. TolÃ©rance aux Pannes</h2>

                <h3>MÃ©canismes de Protection</h3>
                <div class="grid">
                    <div class="grid-item">
                        <h4>ğŸ’“ Heartbeats</h4>
                        <p>Les DataNodes envoient des heartbeats au NameNode toutes les 3 secondes. Si pas de heartbeat pendant 10 minutes â†’ DataNode considÃ©rÃ© comme mort.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ”„ RÃ©-rÃ©plication Automatique</h4>
                        <p>Si un DataNode tombe, le NameNode lance automatiquement la rÃ©plication des blocs manquants vers d'autres DataNodes.</p>
                    </div>
                    <div class="grid-item">
                        <h4>âœ… Checksums</h4>
                        <p>Chaque bloc est accompagnÃ© d'un checksum CRC-32. Ã€ chaque lecture, le checksum est vÃ©rifiÃ© pour dÃ©tecter la corruption.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ“¸ Snapshots</h4>
                        <p>PossibilitÃ© de crÃ©er des snapshots en lecture seule de l'arborescence HDFS pour la protection des donnÃ©es.</p>
                    </div>
                </div>

                <h3>ScÃ©narios de Panne</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Type de Panne</th>
                            <th>Impact</th>
                            <th>RÃ©cupÃ©ration</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Panne d'un DataNode</td>
                            <td>Faible - DonnÃ©es toujours accessibles via rÃ©pliques</td>
                            <td>Automatique - RÃ©-rÃ©plication des blocs</td>
                        </tr>
                        <tr>
                            <td>Panne d'un Rack</td>
                            <td>Faible - RÃ©pliques sur autres racks</td>
                            <td>Automatique - RÃ©-rÃ©plication</td>
                        </tr>
                        <tr>
                            <td>Corruption de Bloc</td>
                            <td>Faible - Lecture depuis rÃ©plique saine</td>
                            <td>Automatique - Bloc corrompu supprimÃ© et rÃ©-rÃ©pliquÃ©</td>
                        </tr>
                        <tr>
                            <td>Panne du NameNode</td>
                            <td><strong>Critique</strong> - Cluster inaccessible</td>
                            <td>Manuelle (sans HA) ou Automatique (avec HA)</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section class="section">
                <h2>ğŸ“ RÃ©sumÃ© de la Partie 2</h2>
                <div class="key-points">
                    <h3>Points ClÃ©s Ã  Retenir</h3>
                    <ul>
                        <li>HDFS utilise une architecture Master (NameNode) / Slaves (DataNodes)</li>
                        <li>Les fichiers sont dÃ©coupÃ©s en blocs de 128 MB (par dÃ©faut)</li>
                        <li>Chaque bloc est rÃ©pliquÃ© 3 fois par dÃ©faut pour la tolÃ©rance aux pannes</li>
                        <li>Le NameNode gÃ¨re les mÃ©tadonnÃ©es, les DataNodes stockent les donnÃ©es</li>
                        <li>Les commandes HDFS sont similaires aux commandes Unix</li>
                        <li>HDFS est optimisÃ© pour les gros fichiers et les accÃ¨s sÃ©quentiels</li>
                        <li>La rÃ©plication et les checksums assurent la fiabilitÃ© des donnÃ©es</li>
                    </ul>
                </div>
            </section>

            <div class="alert alert-success" style="margin-top: 40px;">
                <h4>âœ… PrÃªt pour la Suite ?</h4>
                <p>Vous maÃ®trisez maintenant HDFS, le systÃ¨me de stockage de Hadoop. Dans la partie suivante, nous dÃ©couvrirons <strong>MapReduce</strong>, le paradigme de traitement parallÃ¨le des donnÃ©es.</p>
            </div>
        </div>

        <footer>
            <p>&copy; 2025 Formation Hadoop - Data Engineering | Simplon</p>
            <p><a href="partie3.html">Partie 3 : MapReduce â†’</a></p>
        </footer>
    </div>

    <!-- Prism.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-java.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-sql.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-xml.min.js"></script>
</body>
</html>
