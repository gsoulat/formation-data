<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Partie 7 : D√©ploiement Hadoop sur Azure - Formation Hadoop</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />

    <link rel="stylesheet" href="../assets/styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>‚òÅÔ∏è Partie 7 : D√©ploiement Hadoop sur Azure</h1>
            <p class="subtitle">D√©ployer un cluster Hadoop dans le cloud Microsoft Azure</p>
            <div class="duration">‚è±Ô∏è Dur√©e : 2h30</div>
        </header>

        <nav class="nav-menu">
            <ul>
                <li><a href="../index.html">üè† Accueil</a></li>
                <li><a href="partie6.html">‚Üê Partie 6</a></li>
                <li><a href="partie7.html" class="active">Partie 7</a></li>
                <li><a href="partie8.html">Partie 8 ‚Üí</a></li>
            </ul>
        </nav>

        <div class="content">
            <div class="objectives">
                <h2>üéØ Objectifs d'Apprentissage</h2>
                <ul>
                    <li>Comprendre HDInsight, le service Hadoop manag√© d'Azure</li>
                    <li>Cr√©er un cluster Hadoop sur Azure pas √† pas</li>
                    <li>Configurer le stockage Azure pour HDFS</li>
                    <li>Ex√©cuter des jobs MapReduce sur Azure</li>
                    <li>Monitorer et g√©rer le cluster</li>
                </ul>
            </div>

            <section class="section">
                <h2>‚òÅÔ∏è 1. Introduction √† Azure HDInsight</h2>

                <h3>Qu'est-ce que HDInsight ?</h3>
                <p>
                    <strong>Azure HDInsight</strong> est un service cloud manag√© qui facilite le d√©ploiement et la gestion
                    de clusters Hadoop, Spark, Hive, HBase, et d'autres frameworks Big Data sur Microsoft Azure.
                </p>

                <div class="grid">
                    <div class="grid-item">
                        <h4>‚úÖ Avantages</h4>
                        <ul>
                            <li>D√©ploiement rapide (minutes vs heures)</li>
                            <li>Scalabilit√© √©lastique</li>
                            <li>Paiement √† l'usage</li>
                            <li>Maintenance simplifi√©e</li>
                        </ul>
                    </div>
                    <div class="grid-item">
                        <h4>üí∞ Mod√®le de Tarification</h4>
                        <ul>
                            <li>Facturation par n≈ìud/heure</li>
                            <li>Arr√™t du cluster pour √©conomiser</li>
                            <li>Stockage Azure factur√© s√©par√©ment</li>
                        </ul>
                    </div>
                    <div class="grid-item">
                        <h4>üîß Types de Clusters</h4>
                        <ul>
                            <li>Hadoop (MapReduce, HDFS, YARN)</li>
                            <li>Spark (traitement in-memory)</li>
                            <li>HBase (NoSQL)</li>
                            <li>Interactive Query (Hive LLAP)</li>
                        </ul>
                    </div>
                    <div class="grid-item">
                        <h4>üíæ Stockage</h4>
                        <ul>
                            <li>Azure Blob Storage</li>
                            <li>Azure Data Lake Storage Gen2</li>
                            <li>Compatible HDFS</li>
                        </ul>
                    </div>
                </div>

                <div class="alert alert-info">
                    <h4>Pr√©requis</h4>
                    <ul>
                        <li>Un compte Microsoft Azure (essai gratuit disponible)</li>
                        <li>Cr√©dits Azure (200$ offerts pour les nouveaux comptes)</li>
                        <li>Un abonnement Azure actif</li>
                    </ul>
                </div>
            </section>

            <section class="section">
                <h2>üöÄ 2. Cr√©ation d'un Compte Azure (si n√©cessaire)</h2>

                <h3>√âtape 1 : S'inscrire sur Azure</h3>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># 1. Aller sur https://azure.microsoft.com/free/
# 2. Cliquer sur "Commencer gratuitement"
# 3. Se connecter avec un compte Microsoft (ou en cr√©er un)
# 4. Remplir les informations de facturation (carte requise mais pas d√©bit√©e)
# 5. V√©rifier votre identit√© par t√©l√©phone
# 6. Accepter les conditions</code></pre>
                </div>

                <div class="alert alert-success">
                    <h4>Cr√©dits Gratuits</h4>
                    <p>Nouveau compte Azure = <strong>200$ de cr√©dits valables 30 jours</strong> + services gratuits 12 mois</p>
                </div>

                <h3>√âtape 2 : Acc√©der au Portail Azure</h3>
                <ol>
                    <li>Se connecter sur <a href="https://portal.azure.com">https://portal.azure.com</a></li>
                    <li>V√©rifier que votre abonnement est actif (menu "Abonnements")</li>
                    <li>Vous √™tes pr√™t √† cr√©er votre cluster !</li>
                </ol>
            </section>

            <section class="section">
                <h2>üîß 3. Cr√©ation d'un Cluster HDInsight - Pas √† Pas</h2>

                <h3>√âtape 1 : Cr√©er un Groupe de Ressources</h3>

                <div class="alert alert-info">
                    <h4>Qu'est-ce qu'un Groupe de Ressources ?</h4>
                    <p>
                        Un conteneur logique qui regroupe toutes les ressources Azure li√©es (cluster, stockage, r√©seau).
                        Permet de g√©rer et supprimer facilement toutes les ressources d'un projet.
                    </p>
                </div>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Dans le Portail Azure :

1. Cliquer sur "Groupes de ressources" dans le menu
2. Cliquer sur "+ Cr√©er"
3. Remplir les informations :
   - Abonnement : Votre abonnement Azure
   - Nom du groupe : hadoop-formation-rg
   - R√©gion : France Central (ou la plus proche)
4. Cliquer sur "V√©rifier + cr√©er"
5. Cliquer sur "Cr√©er"</code></pre>
                </div>

                <h3>√âtape 2 : Cr√©er un Compte de Stockage Azure</h3>

                <p>Le cluster HDInsight a besoin d'un stockage pour HDFS.</p>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Dans le Portail Azure :

1. Cliquer sur "+ Cr√©er une ressource"
2. Rechercher "Compte de stockage"
3. Cliquer sur "Cr√©er"
4. Remplir :
   - Groupe de ressources : hadoop-formation-rg
   - Nom du compte : hadoopstorage[votreID] (doit √™tre unique)
   - R√©gion : France Central
   - Performances : Standard
   - Redondance : LRS (Stockage localement redondant)
5. Cliquer sur "V√©rifier + cr√©er"
6. Cliquer sur "Cr√©er"
7. Attendre la fin du d√©ploiement (1-2 minutes)</code></pre>
                </div>

                <h3>√âtape 3 : Cr√©er un Conteneur Blob</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Une fois le compte de stockage cr√©√© :

1. Aller dans le compte de stockage cr√©√©
2. Dans le menu √† gauche, cliquer sur "Conteneurs"
3. Cliquer sur "+ Conteneur"
4. Nom : hadoop-data
5. Niveau d'acc√®s public : Priv√©
6. Cliquer sur "Cr√©er"</code></pre>
                </div>

                <h3>√âtape 4 : Cr√©er le Cluster HDInsight</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Dans le Portail Azure :

1. Cliquer sur "+ Cr√©er une ressource"
2. Rechercher "HDInsight"
3. Cliquer sur "Azure HDInsight"
4. Cliquer sur "Cr√©er"

# Onglet "Informations de base" :
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Abonnement : Votre abonnement
- Groupe de ressources : hadoop-formation-rg
- Nom du cluster : hadoop-cluster-[votreID]
- R√©gion : France Central
- Type de cluster : Hadoop
- Version : Hadoop 3.1.1 (ou la plus r√©cente)
- Nom d'utilisateur du cluster : admin
- Mot de passe : [Cr√©er un mot de passe fort]
  (ex: Hadoop@2025!)
- Nom d'utilisateur SSH : sshuser
- Utiliser le m√™me mot de passe : Oui

Cliquer sur "Suivant : Stockage"

# Onglet "Stockage" :
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Type de stockage principal : Azure Storage
- M√©thode de s√©lection : S√©lectionner dans la liste
- Compte de stockage : hadoopstorage[votreID]
- Conteneur : hadoop-data
- Identit√© manag√©e : (laisser par d√©faut)

Cliquer sur "Suivant : S√©curit√© + r√©seau"

# Onglet "S√©curit√© + r√©seau" :
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Laisser les param√®tres par d√©faut
Cliquer sur "Suivant : Configuration + tarification"

# Onglet "Configuration + tarification" :
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Type de n≈ìud : Standard_D3_v2 (ou Standard_D4_v2)
- Nombre de n≈ìuds Worker : 2
- Nombre de n≈ìuds Head : 2 (d√©faut)

Cliquer sur "Suivant : √âtiquettes" (optionnel)
Cliquer sur "Suivant : V√©rifier + cr√©er"
V√©rifier le r√©capitulatif
Cliquer sur "Cr√©er"</code></pre>
                </div>

                <div class="alert alert-warning">
                    <h4>‚è±Ô∏è Temps de Cr√©ation</h4>
                    <p>
                        La cr√©ation du cluster prend entre <strong>15 et 30 minutes</strong>.
                        Vous pouvez suivre la progression dans les notifications (ic√¥ne cloche en haut √† droite).
                    </p>
                </div>

                <div class="alert alert-danger">
                    <h4>üí∞ Attention aux Co√ªts</h4>
                    <p>
                        Un cluster HDInsight avec 2 n≈ìuds worker co√ªte environ <strong>5-10‚Ç¨/jour</strong>.
                        Pensez √† <strong>supprimer le cluster</strong> apr√®s vos tests pour √©viter les frais !
                    </p>
                </div>
            </section>

            <section class="section">
                <h2>üîå 4. Connexion au Cluster</h2>

                <h3>M√©thode 1 : Interface Web Ambari</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Une fois le cluster cr√©√© :

1. Aller dans votre cluster HDInsight
2. Dans le menu √† gauche, cliquer sur "Tableaux de bord du cluster"
3. Cliquer sur "Ambari home"
4. Se connecter avec :
   - Utilisateur : admin
   - Mot de passe : [le mot de passe que vous avez cr√©√©]

# URL directe :
https://hadoop-cluster-[votreID].azurehdinsight.net</code></pre>
                </div>

                <h3>M√©thode 2 : SSH vers le N≈ìud Head</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Depuis votre terminal local :

ssh sshuser@hadoop-cluster-[votreID]-ssh.azurehdinsight.net

# Entrer le mot de passe SSH
# Vous √™tes maintenant connect√© au n≈ìud Head du cluster !

# V√©rifier Hadoop
hadoop version

# V√©rifier HDFS
hdfs dfs -ls /

# V√©rifier YARN
yarn node -list</code></pre>
                </div>
            </section>

            <section class="section">
                <h2>üìÇ 5. Utiliser le Stockage Azure avec Hadoop</h2>

                <h3>Azure Blob Storage comme HDFS</h3>

                <p>
                    HDInsight utilise Azure Blob Storage comme syst√®me de fichiers par d√©faut,
                    compatible avec les commandes HDFS.
                </p>

                <h4>Format des Chemins</h4>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Format WASB (Windows Azure Storage Blob)
wasb://[conteneur]@[compte-stockage].blob.core.windows.net/[chemin]

# Exemple :
wasb://hadoop-data@hadoopstorage123.blob.core.windows.net/user/data

# Format court (si c'est le stockage par d√©faut)
/user/data</code></pre>
                </div>

                <h4>Commandes HDFS sur Azure Storage</h4>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Lister les fichiers
hdfs dfs -ls /

# Cr√©er un r√©pertoire
hdfs dfs -mkdir /user/sshuser/test

# Cr√©er un fichier local et le copier
echo "Hello Azure Hadoop" > test.txt
hdfs dfs -put test.txt /user/sshuser/

# Lire le fichier
hdfs dfs -cat /user/sshuser/test.txt

# Le fichier est stock√© dans Azure Blob Storage !
# Vous pouvez le voir dans le Portail Azure :
# Compte de stockage ‚Üí Conteneurs ‚Üí hadoop-data</code></pre>
                </div>
            </section>

            <section class="section">
                <h2>üéØ 6. Ex√©cuter un Job MapReduce sur Azure</h2>

                <h3>Exemple : WordCount en Python</h3>

                <h4>√âtape 1 : Cr√©er les Scripts Python</h4>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Connect√© en SSH au cluster

# Cr√©er mapper.py
cat > mapper.py << 'EOF'
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()
    words = line.split()
    for word in words:
        print(f"{word}\t1")
EOF

# Cr√©er reducer.py
cat > reducer.py << 'EOF'
#!/usr/bin/env python3
import sys

current_word = None
current_count = 0

for line in sys.stdin:
    line = line.strip()
    word, count = line.split('\t')
    count = int(count)

    if current_word == word:
        current_count += count
    else:
        if current_word:
            print(f"{current_word}\t{current_count}")
        current_word = word
        current_count = count

if current_word:
    print(f"{current_word}\t{current_count}")
EOF

# Rendre ex√©cutables
chmod +x mapper.py reducer.py</code></pre>
                </div>

                <h4>√âtape 2 : Pr√©parer les Donn√©es</h4>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Cr√©er un fichier de test
cat > input.txt << EOF
Azure Hadoop HDInsight
Cloud Computing with Hadoop
Big Data on Azure
EOF

# Cr√©er le r√©pertoire dans HDFS (Azure Storage)
hdfs dfs -mkdir -p /user/sshuser/wordcount/input

# Copier le fichier
hdfs dfs -put input.txt /user/sshuser/wordcount/input/

# V√©rifier
hdfs dfs -cat /user/sshuser/wordcount/input/input.txt</code></pre>
                </div>

                <h4>√âtape 3 : Lancer le Job</h4>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Lancer le job Hadoop Streaming
hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar \
    -input /user/sshuser/wordcount/input \
    -output /user/sshuser/wordcount/output \
    -mapper mapper.py \
    -reducer reducer.py \
    -file mapper.py \
    -file reducer.py

# Voir les r√©sultats
hdfs dfs -cat /user/sshuser/wordcount/output/part-00000</code></pre>
                </div>

                <h4>√âtape 4 : Suivre le Job dans YARN</h4>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># URL YARN ResourceManager :
https://hadoop-cluster-[votreID].azurehdinsight.net/yarnui

# Se connecter avec :
- Utilisateur : admin
- Mot de passe : [votre mot de passe]</code></pre>
                </div>
            </section>

            <section class="section">
                <h2>üìä 7. Utiliser Hive sur HDInsight</h2>

                <h3>Connexion √† Hive</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Depuis SSH sur le cluster
beeline -u 'jdbc:hive2://localhost:10001/;transportMode=http'

# Ou connectez-vous √† Hive View dans Ambari</code></pre>
                </div>

                <h3>Exemple de Requ√™tes Hive</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-sql">-- Cr√©er une table
CREATE TABLE sales (
    product STRING,
    quantity INT,
    price DOUBLE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

-- Charger des donn√©es depuis Azure Storage
LOAD DATA INPATH '/user/sshuser/sales.csv' INTO TABLE sales;

-- Requ√™te
SELECT product, SUM(quantity * price) as revenue
FROM sales
GROUP BY product
ORDER BY revenue DESC;</code></pre>
                </div>
            </section>

            <section class="section">
                <h2>üîç 8. Monitoring et Gestion</h2>

                <h3>Interfaces de Monitoring</h3>

                <table>
                    <thead>
                        <tr>
                            <th>Interface</th>
                            <th>URL</th>
                            <th>Utilisation</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Ambari</td>
                            <td>https://[cluster].azurehdinsight.net</td>
                            <td>Gestion compl√®te du cluster</td>
                        </tr>
                        <tr>
                            <td>YARN UI</td>
                            <td>https://[cluster].azurehdinsight.net/yarnui</td>
                            <td>Suivi des jobs YARN</td>
                        </tr>
                        <tr>
                            <td>Job History</td>
                            <td>https://[cluster].azurehdinsight.net/jobhistory</td>
                            <td>Historique des jobs</td>
                        </tr>
                        <tr>
                            <td>Portail Azure</td>
                            <td>portal.azure.com</td>
                            <td>M√©triques et alertes</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Scaler le Cluster</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Dans le Portail Azure :

1. Aller dans votre cluster HDInsight
2. Menu √† gauche ‚Üí "Taille du cluster"
3. Modifier le nombre de n≈ìuds Worker (2 √† 10+)
4. Cliquer sur "Enregistrer"
5. Le scaling prend 5-10 minutes</code></pre>
                </div>
            </section>

            <section class="section">
                <h2>üóëÔ∏è 9. Nettoyage et Suppression</h2>

                <div class="alert alert-danger">
                    <h4>‚ö†Ô∏è Important : √âviter les Frais</h4>
                    <p>
                        Apr√®s vos tests, <strong>supprimez le cluster</strong> pour arr√™ter la facturation !
                        Le stockage Azure (quelques centimes) peut √™tre conserv√© si vous voulez garder vos donn√©es.
                    </p>
                </div>

                <h3>Supprimer le Cluster</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># M√©thode 1 : Portail Azure
1. Aller dans votre cluster HDInsight
2. Cliquer sur "Supprimer" en haut
3. Taper le nom du cluster pour confirmer
4. Cliquer sur "Supprimer"

# M√©thode 2 : Azure CLI
az hdinsight delete --name hadoop-cluster-[votreID] --resource-group hadoop-formation-rg

# Pour tout supprimer (cluster + stockage + groupe de ressources) :
az group delete --name hadoop-formation-rg --yes</code></pre>
                </div>

                <h3>V√©rifier les Co√ªts</h3>

                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Dans le Portail Azure :

1. Menu ‚Üí "Cost Management + Billing"
2. ‚Üí "Cost analysis"
3. V√©rifier les co√ªts par ressource
4. V√©rifier qu'aucune ressource n'est en cours d'ex√©cution</code></pre>
                </div>
            </section>

            <section class="section">
                <h2>üìù R√©sum√© de la Partie 7</h2>
                <div class="key-points">
                    <h3>Points Cl√©s √† Retenir</h3>
                    <ul>
                        <li>Azure HDInsight = Hadoop manag√© dans le cloud</li>
                        <li>Cr√©ation d'un cluster en 15-30 minutes via le Portail Azure</li>
                        <li>Azure Blob Storage remplace HDFS (compatible)</li>
                        <li>M√™me commandes Hadoop que sur un cluster local</li>
                        <li>Interfaces Ambari et YARN pour la gestion et le monitoring</li>
                        <li>Scaling facile du nombre de n≈ìuds</li>
                        <li>‚ö†Ô∏è Supprimer le cluster apr√®s usage pour √©viter les frais</li>
                    </ul>
                </div>
            </section>

            <div class="alert alert-success" style="margin-top: 40px;">
                <h4>‚úÖ Pr√™t pour la Suite ?</h4>
                <p>Vous savez maintenant d√©ployer Hadoop sur Azure ! Dans la partie suivante, nous allons pratiquer pas √† pas avec des exercices guid√©s.</p>
            </div>
        </div>

        <footer>
            <p>&copy; 2025 Formation Hadoop - Data Engineering | Simplon</p>
            <p><a href="partie8.html">Partie 8 : Exercices Pratiques Guid√©s ‚Üí</a></p>
        </footer>
    </div>

    <!-- Prism.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-java.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-sql.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-xml.min.js"></script>
</body>
</html>
