<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Partie 3 : MapReduce - Formation Hadoop</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />

    <link rel="stylesheet" href="../assets/styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>âš™ï¸ Partie 3 : MapReduce</h1>
            <p class="subtitle">Le paradigme de traitement distribuÃ© des donnÃ©es</p>
            <div class="duration">â±ï¸ DurÃ©e : 3h30</div>
        </header>

        <nav class="nav-menu">
            <ul>
                <li><a href="../index.html">ğŸ  Accueil</a></li>
                <li><a href="partie2.html">â† Partie 2</a></li>
                <li><a href="partie3.html" class="active">Partie 3</a></li>
                <li><a href="partie4.html">Partie 4 â†’</a></li>
            </ul>
        </nav>

        <div class="content">
            <div class="objectives">
                <h2>ğŸ¯ Objectifs d'Apprentissage</h2>
                <ul>
                    <li>Comprendre le paradigme de programmation MapReduce</li>
                    <li>MaÃ®triser les phases Map, Shuffle et Reduce</li>
                    <li>Ã‰crire un job MapReduce en Java</li>
                    <li>Optimiser les performances MapReduce</li>
                </ul>
            </div>

            <section class="section">
                <h2>ğŸ“š 1. Qu'est-ce que MapReduce ?</h2>

                <p>
                    <strong>MapReduce</strong> est un modÃ¨le de programmation pour traiter et gÃ©nÃ©rer de grands ensembles
                    de donnÃ©es de maniÃ¨re parallÃ¨le et distribuÃ©e sur un cluster.
                </p>

                <div class="alert alert-info">
                    <h4>Principe Fondamental</h4>
                    <p>
                        L'idÃ©e : <strong>"Diviser pour rÃ©gner"</strong> (Divide and Conquer)
                    </p>
                    <ul>
                        <li>DÃ©couper un gros problÃ¨me en petits problÃ¨mes indÃ©pendants</li>
                        <li>Traiter ces petits problÃ¨mes en parallÃ¨le</li>
                        <li>Combiner les rÃ©sultats pour obtenir le rÃ©sultat final</li>
                    </ul>
                </div>

                <h3>Les Deux Fonctions Principales</h3>
                <div class="grid">
                    <div class="grid-item">
                        <h4>ğŸ—ºï¸ Map</h4>
                        <p>Traite les donnÃ©es d'entrÃ©e et produit des paires clÃ©-valeur intermÃ©diaires</p>
                        <code>map: (K1, V1) â†’ list(K2, V2)</code>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ”½ Reduce</h4>
                        <p>Regroupe les valeurs par clÃ© et produit le rÃ©sultat final</p>
                        <code>reduce: (K2, list(V2)) â†’ list(K3, V3)</code>
                    </div>
                </div>

                <h3>Exemple Conceptuel : Compter des Mots</h3>
                <div class="workflow-diagram">
                    <pre>
EntrÃ©e :
  "Hello World"
  "Hello Hadoop"
  "Hadoop MapReduce"

Phase MAP :
  Hello â†’ 1
  World â†’ 1
  Hello â†’ 1
  Hadoop â†’ 1
  Hadoop â†’ 1
  MapReduce â†’ 1

Phase SHUFFLE & SORT :
  Hadoop â†’ [1, 1]
  Hello â†’ [1, 1]
  MapReduce â†’ [1]
  World â†’ [1]

Phase REDUCE :
  Hadoop â†’ 2
  Hello â†’ 2
  MapReduce â†’ 1
  World â†’ 1
                    </pre>
                </div>
            </section>

            <section class="section">
                <h2>ğŸ”„ 2. Architecture et Flux d'ExÃ©cution</h2>

                <h3>Vue d'Ensemble</h3>
                <div class="workflow-diagram">
                    <pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HDFS INPUT DATA                            â”‚
â”‚        Fichiers dÃ©coupÃ©s en blocs (splits)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MAP PHASE                                   â”‚
â”‚  Mapper 1   Mapper 2   Mapper 3   Mapper N                     â”‚
â”‚  (K1,V1)    (K1,V1)    (K1,V1)    (K1,V1)                      â”‚
â”‚    â†“          â†“          â†“          â†“                           â”‚
â”‚  (K2,V2)    (K2,V2)    (K2,V2)    (K2,V2)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SHUFFLE & SORT PHASE                               â”‚
â”‚    Regroupement et tri des paires par clÃ©                       â”‚
â”‚         (K2, list(V2))                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     REDUCE PHASE                                â”‚
â”‚  Reducer 1  Reducer 2  Reducer 3  Reducer M                    â”‚
â”‚  (K2,[V2])  (K2,[V2])  (K2,[V2])  (K2,[V2])                    â”‚
â”‚    â†“          â†“          â†“          â†“                           â”‚
â”‚  (K3,V3)    (K3,V3)    (K3,V3)    (K3,V3)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HDFS OUTPUT DATA                             â”‚
â”‚              RÃ©sultats finaux stockÃ©s                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                </div>

                <h3>Les Phases en DÃ©tail</h3>

                <h4>1ï¸âƒ£ Input Splits</h4>
                <div class="card">
                    <p>Les donnÃ©es d'entrÃ©e sont divisÃ©es en <strong>splits</strong> (morceaux) logiques.</p>
                    <ul>
                        <li>Par dÃ©faut, 1 split = 1 bloc HDFS (128 MB)</li>
                        <li>Chaque split est traitÃ© par un mapper</li>
                        <li>Les mappers s'exÃ©cutent lÃ  oÃ¹ les donnÃ©es sont stockÃ©es (data locality)</li>
                    </ul>
                </div>

                <h4>2ï¸âƒ£ Map Phase</h4>
                <div class="card">
                    <p>Chaque mapper traite un split de donnÃ©es :</p>
                    <ul>
                        <li>Lit les donnÃ©es ligne par ligne (ou enregistrement par enregistrement)</li>
                        <li>Applique la fonction <code>map()</code> dÃ©finie par l'utilisateur</li>
                        <li>Ã‰met des paires clÃ©-valeur intermÃ©diaires</li>
                        <li>Les rÃ©sultats sont Ã©crits dans un buffer en mÃ©moire</li>
                    </ul>
                </div>

                <h4>3ï¸âƒ£ Shuffle & Sort Phase</h4>
                <div class="card">
                    <p>Phase critique gÃ©rÃ©e automatiquement par Hadoop :</p>
                    <ul>
                        <li><strong>Partitioning</strong> : Les paires (K2,V2) sont partitionnÃ©es par clÃ© vers les reducers</li>
                        <li><strong>Sorting</strong> : Les clÃ©s sont triÃ©es</li>
                        <li><strong>Grouping</strong> : Les valeurs avec la mÃªme clÃ© sont regroupÃ©es</li>
                        <li><strong>Transfer</strong> : Les donnÃ©es sont transfÃ©rÃ©es via le rÃ©seau vers les reducers</li>
                    </ul>
                    <p><em>Cette phase consomme beaucoup de ressources rÃ©seau et disque.</em></p>
                </div>

                <h4>4ï¸âƒ£ Reduce Phase</h4>
                <div class="card">
                    <p>Chaque reducer traite un ensemble de clÃ©s :</p>
                    <ul>
                        <li>ReÃ§oit les paires (K2, list(V2)) triÃ©es</li>
                        <li>Applique la fonction <code>reduce()</code> dÃ©finie par l'utilisateur</li>
                        <li>Ã‰met les paires clÃ©-valeur finales (K3, V3)</li>
                        <li>Ã‰crit les rÃ©sultats dans HDFS</li>
                    </ul>
                </div>
            </section>

            <section class="section">
                <h2>ğŸ’» 3. WordCount : L'Exemple Classique avec Python</h2>

                <p>Le "Hello World" de MapReduce : compter les occurrences de chaque mot dans un corpus de texte.</p>

                <div class="alert alert-info">
                    <h4>Hadoop Streaming</h4>
                    <p>
                        <strong>Hadoop Streaming</strong> permet d'Ã©crire des jobs MapReduce en Python (ou tout autre langage).
                        Les scripts lisent depuis stdin et Ã©crivent vers stdout.
                    </p>
                </div>

                <h3>Code Python Complet</h3>

                <h4>mapper.py</h4>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-python">#!/usr/bin/env python3
"""
Mapper pour WordCount
Lit les lignes depuis stdin, dÃ©coupe en mots et Ã©met (mot, 1)
"""
import sys

def main():
    # Lire depuis stdin
    for line in sys.stdin:
        # Supprimer les espaces en dÃ©but/fin
        line = line.strip()

        # DÃ©couper la ligne en mots
        words = line.split()

        # Ã‰mettre (mot, 1) pour chaque mot
        for word in words:
            # Format: clÃ©\tvaleur
            print(f"{word}\t1")

if __name__ == "__main__":
    main()</code></pre>
                </div>

                <h4>reducer.py</h4>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-python">#!/usr/bin/env python3
"""
Reducer pour WordCount
ReÃ§oit les paires (mot, 1) triÃ©es par clÃ© et calcule la somme
"""
import sys

def main():
    current_word = None
    current_count = 0

    # Lire depuis stdin
    for line in sys.stdin:
        # Supprimer les espaces
        line = line.strip()

        # Parser la ligne (format: mot\t1)
        try:
            word, count = line.split('\t')
            count = int(count)
        except ValueError:
            # Ignorer les lignes mal formÃ©es
            continue

        # Hadoop trie les clÃ©s, donc les mÃªmes mots sont consÃ©cutifs
        if current_word == word:
            current_count += count
        else:
            # Nouveau mot rencontrÃ©
            if current_word:
                # Ã‰mettre le rÃ©sultat pour le mot prÃ©cÃ©dent
                print(f"{current_word}\t{current_count}")

            current_word = word
            current_count = count

    # Ã‰mettre le dernier mot
    if current_word:
        print(f"{current_word}\t{current_count}")

if __name__ == "__main__":
    main()</code></pre>
                </div>

                <h3>Test Local (avant Hadoop)</h3>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># Rendre les scripts exÃ©cutables
chmod +x mapper.py reducer.py

# Test du mapper seul
echo "Hello World Hello Hadoop" | ./mapper.py

# Sortie attendue:
# Hello   1
# World   1
# Hello   1
# Hadoop  1

# Test complet avec tri (simule Hadoop)
echo "Hello World Hello Hadoop" | ./mapper.py | sort -k1,1 | ./reducer.py

# Sortie attendue:
# Hadoop  1
# Hello   2
# World   1</code></pre>
                </div>

                <h3>ExÃ©cution sur Hadoop</h3>

                <h4>PrÃ©parer les DonnÃ©es</h4>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># CrÃ©er un fichier de test
cat > input.txt << EOF
Hello World Hello Hadoop
Hadoop is powerful
Python and Hadoop
EOF

# CrÃ©er le rÃ©pertoire dans HDFS
hdfs dfs -mkdir -p /user/$USER/wordcount/input

# Copier le fichier dans HDFS
hdfs dfs -put input.txt /user/$USER/wordcount/input/

# VÃ©rifier
hdfs dfs -cat /user/$USER/wordcount/input/input.txt</code></pre>
                </div>

                <h4>Lancer le Job MapReduce avec Hadoop Streaming</h4>
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-dot red"></span>
                        <span class="code-dot yellow"></span>
                        <span class="code-dot green"></span>
                    </div>
                    <pre><code class="language-bash"># ExÃ©cuter le job Hadoop Streaming
hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \
    -input /user/$USER/wordcount/input \
    -output /user/$USER/wordcount/output \
    -mapper mapper.py \
    -reducer reducer.py \
    -file mapper.py \
    -file reducer.py

# Voir les rÃ©sultats
hdfs dfs -cat /user/$USER/wordcount/output/part-00000

# RÃ©sultat attendu :
# Hadoop  3
# Hello   2
# Python  1
# World   1
# and     1
# is      1
# powerful 1</code></pre>
                </div>

                <div class="alert alert-success">
                    <h4>Avantages de Python avec Hadoop</h4>
                    <ul>
                        <li>âœ… Code plus simple et lisible que Java</li>
                        <li>âœ… Pas de compilation nÃ©cessaire</li>
                        <li>âœ… Riche Ã©cosystÃ¨me de librairies Python</li>
                        <li>âœ… Test facile en local avant Hadoop</li>
                        <li>âœ… IdÃ©al pour le prototypage rapide</li>
                    </ul>
                </div>
            </section>

            <section class="section">
                <h2>âš¡ 4. Optimisations MapReduce</h2>

                <h3>Combiner</h3>
                <div class="card">
                    <h4>Qu'est-ce qu'un Combiner ?</h4>
                    <p>
                        Un <strong>Combiner</strong> est comme un "mini-reducer" qui s'exÃ©cute localement sur chaque mapper
                        pour rÃ©duire la quantitÃ© de donnÃ©es transfÃ©rÃ©es durant la phase Shuffle.
                    </p>
                    <div class="code-container">
                        <div class="code-header">
                            <span class="code-dot red"></span>
                            <span class="code-dot yellow"></span>
                            <span class="code-dot green"></span>
                        </div>
                        <pre><code class="language-java">// Dans le Driver
job.setCombinerClass(WordCountReducer.class);</code></pre>
                    </div>
                    <p>
                        <strong>Avantage :</strong> Pour WordCount, au lieu de transfÃ©rer ["Hello"â†’1, "Hello"â†’1, "Hello"â†’1],
                        on transfÃ¨re juste ["Hello"â†’3].
                    </p>
                </div>

                <h3>Partitioner PersonnalisÃ©</h3>
                <div class="card">
                    <p>
                        Le <strong>Partitioner</strong> dÃ©cide quel reducer recevra quelle clÃ©.
                        Par dÃ©faut : <code>HashPartitioner</code> utilise le hashcode de la clÃ©.
                    </p>
                    <div class="code-container">
                        <div class="code-header">
                            <span class="code-dot red"></span>
                            <span class="code-dot yellow"></span>
                            <span class="code-dot green"></span>
                        </div>
                        <pre><code class="language-java">public class CustomPartitioner extends Partitioner&lt;Text, IntWritable&gt; {
    @Override
    public int getPartition(Text key, IntWritable value, int numPartitions) {
        // Exemple : mots commenÃ§ant par A-M â†’ Reducer 0
        //           mots commenÃ§ant par N-Z â†’ Reducer 1
        char firstLetter = key.toString().charAt(0);
        if (firstLetter >= 'A' && firstLetter <= 'M') {
            return 0 % numPartitions;
        } else {
            return 1 % numPartitions;
        }
    }
}</code></pre>
                    </div>
                </div>

                <h3>Compression</h3>
                <div class="card">
                    <p>Compresser les donnÃ©es intermÃ©diaires et de sortie rÃ©duit l'utilisation disque et rÃ©seau.</p>
                    <div class="code-container">
                        <div class="code-header">
                            <span class="code-dot red"></span>
                            <span class="code-dot yellow"></span>
                            <span class="code-dot green"></span>
                        </div>
                        <pre><code class="language-java">// Compression des donnÃ©es intermÃ©diaires (Map output)
conf.setBoolean("mapreduce.map.output.compress", true);
conf.setClass("mapreduce.map.output.compress.codec",
              SnappyCodec.class, CompressionCodec.class);

// Compression de la sortie finale
FileOutputFormat.setCompressOutput(job, true);
FileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);</code></pre>
                    </div>
                </div>

                <h3>Autres Optimisations</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Technique</th>
                            <th>Description</th>
                            <th>Impact</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Augmenter le nombre de reducers</strong></td>
                            <td>Plus de reducers = plus de parallÃ©lisme</td>
                            <td>âš¡ Performance accrue si le cluster le permet</td>
                        </tr>
                        <tr>
                            <td><strong>RÃ©utiliser la JVM</strong></td>
                            <td>Ã‰viter le coÃ»t de dÃ©marrage de JVM pour chaque tÃ¢che</td>
                            <td>â±ï¸ RÃ©duction du temps de lancement</td>
                        </tr>
                        <tr>
                            <td><strong>ExÃ©cution spÃ©culative</strong></td>
                            <td>Relancer les tÃ¢ches lentes sur d'autres nÅ“uds</td>
                            <td>ğŸš€ RÃ©duit l'impact des "stragglers"</td>
                        </tr>
                        <tr>
                            <td><strong>Buffer d'Ã©criture Map</strong></td>
                            <td>Augmenter <code>mapreduce.task.io.sort.mb</code></td>
                            <td>ğŸ’¾ Moins de spills sur disque</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section class="section">
                <h2>ğŸ“Š 5. Patterns MapReduce Courants</h2>

                <h3>1. Filtering (Filtrage)</h3>
                <div class="card">
                    <p>Garder seulement les enregistrements qui rÃ©pondent Ã  un critÃ¨re.</p>
                    <p><strong>Exemple :</strong> Filtrer les logs d'erreur</p>
                    <ul>
                        <li>Map : Si ligne contient "ERROR" â†’ Ã©mettre</li>
                        <li>Reduce : Peut Ãªtre omis (identity reducer)</li>
                    </ul>
                </div>

                <h3>2. Summarization (AgrÃ©gation)</h3>
                <div class="card">
                    <p>Calculer des statistiques agrÃ©gÃ©es (count, sum, avg, min, max).</p>
                    <p><strong>Exemple :</strong> Statistiques par utilisateur</p>
                    <ul>
                        <li>Map : (user_id, metric) â†’ Ã©mettre</li>
                        <li>Reduce : Calculer somme, moyenne, etc.</li>
                    </ul>
                </div>

                <h3>3. Joining (Jointure)</h3>
                <div class="card">
                    <p>Joindre deux datasets sur une clÃ© commune.</p>
                    <p><strong>Reduce-side join :</strong></p>
                    <ul>
                        <li>Map : Ã‰mettre (clÃ©_commune, valeur_avec_tag)</li>
                        <li>Reduce : Regrouper et joindre les valeurs avec la mÃªme clÃ©</li>
                    </ul>
                </div>

                <h3>4. Sorting (Tri)</h3>
                <div class="card">
                    <p>Trier des donnÃ©es Ã  grande Ã©chelle.</p>
                    <ul>
                        <li>Map : Ã‰mettre (clÃ©_de_tri, enregistrement)</li>
                        <li>Reduce : Peut Ãªtre identity (le tri est fait durant Shuffle)</li>
                    </ul>
                </div>

                <h3>5. Top N</h3>
                <div class="card">
                    <p>Trouver les N premiers Ã©lÃ©ments.</p>
                    <ul>
                        <li>Map : Garder top N localement, Ã©mettre</li>
                        <li>Reduce : Fusionner et garder top N global</li>
                    </ul>
                </div>
            </section>

            <section class="section">
                <h2>âš ï¸ 6. Limites de MapReduce</h2>

                <div class="grid">
                    <div class="grid-item">
                        <h4>ğŸŒ Latence Ã‰levÃ©e</h4>
                        <p>Pas adaptÃ© au temps rÃ©el. Temps de dÃ©marrage et I/O disque importants.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ’¾ I/O Intensif</h4>
                        <p>Ã‰crit et lit beaucoup sur disque (HDFS), pas en mÃ©moire.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ”— Jobs ChaÃ®nÃ©s Complexes</h4>
                        <p>Difficile de chaÃ®ner plusieurs jobs MapReduce efficacement.</p>
                    </div>
                    <div class="grid-item">
                        <h4>ğŸ“ˆ Pas AdaptÃ© aux Graphes</h4>
                        <p>Algorithmes itÃ©ratifs (ML, graphes) sont inefficaces.</p>
                    </div>
                </div>

                <div class="alert alert-warning">
                    <h4>Alternative : Apache Spark</h4>
                    <p>
                        <strong>Spark</strong> a Ã©tÃ© crÃ©Ã© pour pallier les limites de MapReduce :
                    </p>
                    <ul>
                        <li>Traitement en mÃ©moire (100x plus rapide)</li>
                        <li>API plus simple et expressive</li>
                        <li>Support natif du streaming, ML, graphes</li>
                        <li>Compatible avec HDFS et YARN</li>
                    </ul>
                    <p><em>Cependant, MapReduce reste utilisÃ© pour certains cas d'usage batch intensifs.</em></p>
                </div>
            </section>

            <section class="section">
                <h2>ğŸ“ RÃ©sumÃ© de la Partie 3</h2>
                <div class="key-points">
                    <h3>Points ClÃ©s Ã  Retenir</h3>
                    <ul>
                        <li>MapReduce suit le paradigme "Diviser pour rÃ©gner"</li>
                        <li>3 phases principales : Map, Shuffle & Sort, Reduce</li>
                        <li>WordCount est l'exemple canonique de MapReduce</li>
                        <li>Les Combiners rÃ©duisent le trafic rÃ©seau</li>
                        <li>La compression amÃ©liore les performances</li>
                        <li>MapReduce est excellent pour le batch mais pas pour le temps rÃ©el</li>
                        <li>Spark est souvent prÃ©fÃ©rÃ© pour les nouveaux projets</li>
                    </ul>
                </div>
            </section>

            <div class="alert alert-success" style="margin-top: 40px;">
                <h4>âœ… PrÃªt pour la Suite ?</h4>
                <p>Vous maÃ®trisez maintenant MapReduce ! Dans la partie suivante, nous dÃ©couvrirons <strong>YARN</strong>, le gestionnaire de ressources qui orchestre l'exÃ©cution des applications Hadoop.</p>
            </div>
        </div>

        <footer>
            <p>&copy; 2025 Formation Hadoop - Data Engineering | Simplon</p>
            <p><a href="partie4.html">Partie 4 : YARN â†’</a></p>
        </footer>
    </div>

    <!-- Prism.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-java.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-sql.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-xml.min.js"></script>
</body>
</html>
