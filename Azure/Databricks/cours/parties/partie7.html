<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Partie 7 : Machine Learning et MLflow</title>
    <link rel="stylesheet" href="../assets/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸš€ Partie 7 : Machine Learning et MLflow</h1>
            <p class="subtitle">ML lifecycle management sur Databricks</p>
            <span class="duration">â±ï¸ DurÃ©e : 50 minutes</span>
        </header>

        <nav class="nav-menu">
            <ul>
                <li><a href="../index.html">ğŸ  Accueil</a></li>
                <li><a href="partie6.html">â† Partie 6</a></li>
                <li><a href="partie7.html" class="active">Partie 7</a></li>
            </ul>
        </nav>

        <div class="content">
            <section class="objectives">
                <h2>ğŸ¯ Objectifs d'apprentissage</h2>
                <ul>
                    <li>Comprendre MLflow et son rÃ´le dans le ML lifecycle</li>
                    <li>Tracker des expÃ©riences ML avec MLflow Tracking</li>
                    <li>GÃ©rer des modÃ¨les avec MLflow Model Registry</li>
                    <li>DÃ©ployer et servir des modÃ¨les ML</li>
                    <li>Utiliser AutoML pour accÃ©lÃ©rer le dÃ©veloppement</li>
                    <li>ImplÃ©menter MLOps sur Databricks</li>
                </ul>
            </section>

            <section class="section">
                <h2>1. Introduction Ã  MLflow</h2>

                <p>MLflow est une <strong>plateforme open source</strong> pour gÃ©rer l'intÃ©gralitÃ© du cycle de vie du Machine Learning. Databricks intÃ¨gre nativement MLflow avec des fonctionnalitÃ©s avancÃ©es.</p>

                <h3>Composants de MLflow</h3>
                <div class="grid">
                    <div class="grid-item">
                        <h4>MLflow Tracking</h4>
                        <p>Enregistrement des expÃ©riences, paramÃ¨tres, mÃ©triques et artefacts</p>
                    </div>
                    <div class="grid-item">
                        <h4>MLflow Projects</h4>
                        <p>Format standardisÃ© pour packager le code ML rÃ©utilisable</p>
                    </div>
                    <div class="grid-item">
                        <h4>MLflow Models</h4>
                        <p>Format standard pour packager les modÃ¨les ML</p>
                    </div>
                    <div class="grid-item">
                        <h4>Model Registry</h4>
                        <p>Store centralisÃ© pour gÃ©rer les versions et le lifecycle des modÃ¨les</p>
                    </div>
                </div>

                <div class="workflow-diagram">
                    <pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML LIFECYCLE WITH MLFLOW                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Data Prep     â”‚ â”€â”€â”€â–¶ â”‚ Experimentationâ”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                  â”‚                           â”‚
â”‚                                  â–¼                           â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                         â”‚ MLflow Trackingâ”‚                   â”‚
â”‚                         â”‚  â€¢ Params      â”‚                   â”‚
â”‚                         â”‚  â€¢ Metrics     â”‚                   â”‚
â”‚                         â”‚  â€¢ Models      â”‚                   â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                 â”‚                            â”‚
â”‚                                 â–¼                            â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                        â”‚ Model Registry â”‚                    â”‚
â”‚                        â”‚  â€¢ None        â”‚                    â”‚
â”‚                        â”‚  â€¢ Staging     â”‚                    â”‚
â”‚                        â”‚  â€¢ Production  â”‚                    â”‚
â”‚                        â”‚  â€¢ Archived    â”‚                    â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                â”‚                             â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                     â–¼                     â–¼                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚              â”‚ Batch Infer â”‚      â”‚ Real-time   â”‚          â”‚
â”‚              â”‚             â”‚      â”‚ Serving     â”‚          â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>
                </div>
            </section>

            <section class="section">
                <h2>2. MLflow Tracking</h2>

                <h3>Enregistrer une expÃ©rience simple</h3>
                <pre><code class="language-python">import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
import pandas as pd

# Charger les donnÃ©es
df = spark.read.table("customer_churn").toPandas()
X = df.drop("churn", axis=1)
y = df["churn"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# DÃ©marrer une run MLflow
with mlflow.start_run(run_name="rf_baseline") as run:

    # Log des paramÃ¨tres
    n_estimators = 100
    max_depth = 10

    mlflow.log_param("n_estimators", n_estimators)
    mlflow.log_param("max_depth", max_depth)
    mlflow.log_param("model_type", "RandomForest")

    # EntraÃ®nement
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=42
    )
    model.fit(X_train, y_train)

    # PrÃ©dictions
    y_pred = model.predict(X_test)

    # Log des mÃ©triques
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("f1_score", f1)

    # Log du modÃ¨le
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="customer_churn_classifier"
    )

    # Log d'artefacts (fichiers)
    import matplotlib.pyplot as plt
    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    plt.savefig("confusion_matrix.png")
    mlflow.log_artifact("confusion_matrix.png")

    print(f"Run ID: {run.info.run_id}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1 Score: {f1:.4f}")
</code></pre>

                <h3>Tracking avec plusieurs expÃ©riences</h3>
                <pre><code class="language-python">from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier

# CrÃ©er ou rÃ©cupÃ©rer une expÃ©rience
experiment_name = "/Users/me@company.com/churn_prediction"
mlflow.set_experiment(experiment_name)

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100),
    "XGBoost": XGBClassifier(n_estimators=100, use_label_encoder=False)
}

results = []

for model_name, model in models.items():
    with mlflow.start_run(run_name=model_name):

        # Tags pour organisation
        mlflow.set_tag("model_family", model_name.split()[0])
        mlflow.set_tag("developer", "data_team")

        # EntraÃ®nement
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # MÃ©triques
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

        mlflow.log_metric("accuracy", accuracy)
        mlflow.log_metric("f1_score", f1)

        # Log modÃ¨le
        mlflow.sklearn.log_model(model, "model")

        results.append({
            "model": model_name,
            "accuracy": accuracy,
            "f1_score": f1
        })

        print(f"{model_name}: Accuracy={accuracy:.4f}, F1={f1:.4f}")

# Comparer les rÃ©sultats
results_df = pd.DataFrame(results).sort_values("f1_score", ascending=False)
display(results_df)
</code></pre>

                <h3>Rechercher et comparer des runs</h3>
                <pre><code class="language-python"># Rechercher des runs par filtre
from mlflow.tracking import MlflowClient

client = MlflowClient()

# Obtenir l'expÃ©rience
experiment = client.get_experiment_by_name(experiment_name)

# Rechercher les runs avec un filtre
runs = mlflow.search_runs(
    experiment_ids=[experiment.experiment_id],
    filter_string="metrics.accuracy > 0.85",
    order_by=["metrics.f1_score DESC"],
    max_results=10
)

display(runs[["run_id", "start_time", "params.model_type", "metrics.accuracy", "metrics.f1_score"]])

# Obtenir les dÃ©tails d'un run spÃ©cifique
run_id = "abc123..."
run = client.get_run(run_id)
print(f"ParamÃ¨tres: {run.data.params}")
print(f"MÃ©triques: {run.data.metrics}")
</code></pre>
            </section>

            <section class="section">
                <h2>3. MLflow Model Registry</h2>

                <p>Le Model Registry est un store centralisÃ© pour gÃ©rer les versions et le lifecycle des modÃ¨les ML.</p>

                <h3>Enregistrer un modÃ¨le</h3>
                <pre><code class="language-python"># MÃ©thode 1 : Lors du log
with mlflow.start_run():
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="customer_churn_classifier"
    )

# MÃ©thode 2 : Depuis un run existant
run_id = "abc123..."
model_uri = f"runs:/{run_id}/model"

mlflow.register_model(
    model_uri=model_uri,
    name="customer_churn_classifier"
)
</code></pre>

                <h3>GÃ©rer les versions et stages</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Stage</th>
                            <th>Description</th>
                            <th>Utilisation</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>None</strong></td>
                            <td>Nouvellement enregistrÃ©</td>
                            <td>ModÃ¨le en dÃ©veloppement</td>
                        </tr>
                        <tr>
                            <td><strong>Staging</strong></td>
                            <td>En test/validation</td>
                            <td>Tests UAT, A/B testing</td>
                        </tr>
                        <tr>
                            <td><strong>Production</strong></td>
                            <td>DÃ©ployÃ© en production</td>
                            <td>Serving en production</td>
                        </tr>
                        <tr>
                            <td><strong>Archived</strong></td>
                            <td>ArchivÃ©/obsolÃ¨te</td>
                            <td>ModÃ¨les retirÃ©s</td>
                        </tr>
                    </tbody>
                </table>

                <pre><code class="language-python">from mlflow.tracking import MlflowClient

client = MlflowClient()
model_name = "customer_churn_classifier"

# Promouvoir une version en Staging
client.transition_model_version_stage(
    name=model_name,
    version=3,
    stage="Staging",
    archive_existing_versions=False
)

# Promouvoir en Production (et archiver les anciennes versions)
client.transition_model_version_stage(
    name=model_name,
    version=3,
    stage="Production",
    archive_existing_versions=True  # Archive les anciennes versions en Production
)

# Ajouter une description
client.update_model_version(
    name=model_name,
    version=3,
    description="ModÃ¨le entraÃ®nÃ© sur donnÃ©es Q1 2024, accuracy=0.92, dÃ©ployÃ© le 2024-01-15"
)

# Lister toutes les versions
versions = client.search_model_versions(f"name='{model_name}'")
for v in versions:
    print(f"Version {v.version}: {v.current_stage} - {v.description}")
</code></pre>

                <h3>Charger un modÃ¨le depuis le Registry</h3>
                <pre><code class="language-python"># Charger la version Production
model_production = mlflow.pyfunc.load_model(
    model_uri=f"models:/{model_name}/Production"
)

# Charger une version spÃ©cifique
model_v3 = mlflow.pyfunc.load_model(
    model_uri=f"models:/{model_name}/3"
)

# PrÃ©diction
predictions = model_production.predict(X_test)
</code></pre>
            </section>

            <section class="section">
                <h2>4. AutoML avec Databricks</h2>

                <p>Databricks AutoML automatise l'entraÃ®nement et le tuning de modÃ¨les ML pour accÃ©lÃ©rer le dÃ©veloppement.</p>

                <h3>Utiliser AutoML via l'interface</h3>
                <div class="exercise">
                    <h4>Lancer une expÃ©rience AutoML</h4>
                    <ol>
                        <li>Dans la barre latÃ©rale, cliquez sur <code>Machine Learning</code></li>
                        <li>Cliquez sur <code>AutoML</code></li>
                        <li>SÃ©lectionnez votre table de donnÃ©es</li>
                        <li>Choisissez le type de problÃ¨me :
                            <ul>
                                <li>Classification</li>
                                <li>Regression</li>
                                <li>Forecasting</li>
                            </ul>
                        </li>
                        <li>SÃ©lectionnez la colonne cible (label)</li>
                        <li>Configurez les paramÃ¨tres avancÃ©s (optionnel)</li>
                        <li>Cliquez sur <code>Start AutoML</code></li>
                    </ol>
                </div>

                <h3>AutoML avec Python API</h3>
                <pre><code class="language-python">from databricks import automl

# Configuration AutoML pour classification
summary = automl.classify(
    dataset=df,
    target_col="churn",
    primary_metric="f1",
    timeout_minutes=30,
    max_trials=20
)

# RÃ©sultats
print(f"Best trial: {summary.best_trial}")
print(f"Best model URI: {summary.best_trial.model_path}")
print(f"Best F1 score: {summary.best_trial.metrics['test_f1_score']}")

# Le meilleur modÃ¨le est automatiquement enregistrÃ© dans MLflow
# Vous pouvez le charger et l'utiliser
best_model = mlflow.pyfunc.load_model(summary.best_trial.model_path)
</code></pre>

                <h3>Ce que fait AutoML</h3>
                <div class="grid">
                    <div class="grid-item">
                        <h4>Data Preprocessing</h4>
                        <ul>
                            <li>Feature engineering automatique</li>
                            <li>Encodage de variables catÃ©gorielles</li>
                            <li>Gestion des valeurs manquantes</li>
                        </ul>
                    </div>
                    <div class="grid-item">
                        <h4>Model Selection</h4>
                        <ul>
                            <li>Teste plusieurs algorithmes</li>
                            <li>Hyperparameter tuning</li>
                            <li>Cross-validation</li>
                        </ul>
                    </div>
                    <div class="grid-item">
                        <h4>Explainability</h4>
                        <ul>
                            <li>Feature importance</li>
                            <li>SHAP values</li>
                            <li>Visualisations</li>
                        </ul>
                    </div>
                    <div class="grid-item">
                        <h4>Notebooks Generated</h4>
                        <ul>
                            <li>Data exploration</li>
                            <li>Best model notebook</li>
                            <li>Code rÃ©utilisable</li>
                        </ul>
                    </div>
                </div>
            </section>

            <section class="section">
                <h2>5. DÃ©ploiement et serving</h2>

                <h3>Batch Inference</h3>
                <pre><code class="language-python"># Charger le modÃ¨le Production
model = mlflow.pyfunc.load_model(f"models:/{model_name}/Production")

# Charger de nouvelles donnÃ©es
new_data = spark.read.table("new_customers")
new_data_pandas = new_data.toPandas()

# PrÃ©dictions batch
predictions = model.predict(new_data_pandas)

# Ajouter les prÃ©dictions au DataFrame
new_data_pandas["churn_prediction"] = predictions
new_data_pandas["prediction_date"] = pd.Timestamp.now()

# Sauvegarder les rÃ©sultats
spark.createDataFrame(new_data_pandas) \
    .write \
    .format("delta") \
    .mode("append") \
    .saveAsTable("churn_predictions")
</code></pre>

                <h3>Model Serving (Real-time)</h3>
                <pre><code class="language-python"># Via l'interface Databricks
# 1. Aller dans Machine Learning â†’ Models
# 2. SÃ©lectionner votre modÃ¨le
# 3. Onglet "Serving"
# 4. Cliquer "Enable Serving"
# 5. Configurer : Workload size, Scale-out

# Une fois dÃ©ployÃ©, vous obtenez une API REST endpoint

# Appeler le endpoint
import requests
import json

# Token d'authentification Databricks
token = dbutils.notebook.entry_point.getDbutils() \
    .notebook().getContext().apiToken().get()

# Endpoint du modÃ¨le
serving_endpoint = "https://<workspace-url>/serving-endpoints/customer_churn_classifier/invocations"

# DonnÃ©es d'entrÃ©e
input_data = {
    "dataframe_records": [
        {"age": 35, "tenure": 12, "monthly_charges": 65.5, "total_charges": 786.0},
        {"age": 42, "tenure": 24, "monthly_charges": 89.3, "total_charges": 2143.2}
    ]
}

# RequÃªte
response = requests.post(
    serving_endpoint,
    headers={"Authorization": f"Bearer {token}"},
    json=input_data
)

predictions = response.json()
print(predictions)
# Output: {"predictions": [0, 1]}
</code></pre>

                <h3>Utilisation via Spark UDF (Inference distribuÃ©e)</h3>
                <pre><code class="language-python">import mlflow.pyfunc

# CrÃ©er une UDF depuis le modÃ¨le
model_udf = mlflow.pyfunc.spark_udf(
    spark,
    model_uri=f"models:/{model_name}/Production",
    result_type="double"
)

# Appliquer le modÃ¨le sur un grand DataFrame Spark
large_df = spark.read.table("all_customers")

predictions_df = large_df.withColumn(
    "churn_prediction",
    model_udf(*[col(c) for c in feature_cols])
)

display(predictions_df)

# Sauvegarder
predictions_df.write.format("delta").mode("overwrite").saveAsTable("customer_predictions")
</code></pre>
            </section>

            <section class="section">
                <h2>6. MLOps et CI/CD</h2>

                <h3>Workflow MLOps complet</h3>
                <div class="workflow-diagram">
                    <pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MLOPS WORKFLOW                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  1. [Development]                                            â”‚
â”‚     â€¢ Feature Engineering                                    â”‚
â”‚     â€¢ Model Training (MLflow Tracking)                       â”‚
â”‚     â€¢ Experimentation                                        â”‚
â”‚                   â”‚                                          â”‚
â”‚                   â–¼                                          â”‚
â”‚  2. [Version Control]                                        â”‚
â”‚     â€¢ Git commit (code + config)                             â”‚
â”‚     â€¢ Register Model in MLflow Registry                      â”‚
â”‚                   â”‚                                          â”‚
â”‚                   â–¼                                          â”‚
â”‚  3. [CI/CD Pipeline]                                         â”‚
â”‚     â€¢ Run unit tests                                         â”‚
â”‚     â€¢ Train model on CI                                      â”‚
â”‚     â€¢ Model validation tests                                 â”‚
â”‚                   â”‚                                          â”‚
â”‚                   â–¼                                          â”‚
â”‚  4. [Staging Deployment]                                     â”‚
â”‚     â€¢ Transition to "Staging"                                â”‚
â”‚     â€¢ A/B testing                                            â”‚
â”‚     â€¢ Performance monitoring                                 â”‚
â”‚                   â”‚                                          â”‚
â”‚                   â–¼                                          â”‚
â”‚  5. [Production Deployment]                                  â”‚
â”‚     â€¢ Transition to "Production"                             â”‚
â”‚     â€¢ Enable Model Serving                                   â”‚
â”‚     â€¢ Monitor metrics                                        â”‚
â”‚                   â”‚                                          â”‚
â”‚                   â–¼                                          â”‚
â”‚  6. [Monitoring & Retraining]                                â”‚
â”‚     â€¢ Data drift detection                                   â”‚
â”‚     â€¢ Performance degradation alerts                         â”‚
â”‚     â€¢ Trigger retraining pipeline                            â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>
                </div>

                <h3>Exemple de workflow automatisÃ©</h3>
                <pre><code class="language-python"># Notebook 1: Training Pipeline
import mlflow
from datetime import datetime

# Configuration
model_name = "customer_churn_classifier"
min_accuracy_threshold = 0.85

# EntraÃ®nement
with mlflow.start_run(run_name=f"training_{datetime.now().strftime('%Y%m%d')}"):

    # ... code d'entraÃ®nement ...

    # Enregistrer le modÃ¨le
    if accuracy > min_accuracy_threshold:
        model_version = mlflow.register_model(
            model_uri=f"runs:/{mlflow.active_run().info.run_id}/model",
            name=model_name
        )

        # Transition automatique vers Staging
        client.transition_model_version_stage(
            name=model_name,
            version=model_version.version,
            stage="Staging"
        )

        print(f"ModÃ¨le version {model_version.version} dÃ©ployÃ© en Staging")
    else:
        print(f"Accuracy {accuracy} < seuil {min_accuracy_threshold}. ModÃ¨le non dÃ©ployÃ©.")
</code></pre>

                <pre><code class="language-python"># Notebook 2: Validation et promotion
from mlflow.tracking import MlflowClient

client = MlflowClient()

# RÃ©cupÃ©rer la derniÃ¨re version Staging
staging_versions = client.get_latest_versions(model_name, stages=["Staging"])
staging_version = staging_versions[0]

# Charger et tester sur validation set
model = mlflow.pyfunc.load_model(f"models:/{model_name}/Staging")
val_predictions = model.predict(X_val)
val_accuracy = accuracy_score(y_val, val_predictions)

# Promotion vers Production si validation OK
if val_accuracy > 0.90:
    client.transition_model_version_stage(
        name=model_name,
        version=staging_version.version,
        stage="Production",
        archive_existing_versions=True
    )

    # Notification
    print(f"âœ… ModÃ¨le version {staging_version.version} dÃ©ployÃ© en Production!")
    # Envoyer email/Slack notification
else:
    print(f"âŒ Validation Ã©chouÃ©e. Accuracy: {val_accuracy}")
</code></pre>

                <h3>Monitoring des modÃ¨les</h3>
                <pre><code class="language-python"># DÃ©tecter le data drift
from scipy.stats import ks_2samp

# DonnÃ©es d'entraÃ®nement
train_data = spark.read.table("training_data").toPandas()

# DonnÃ©es de production rÃ©centes
prod_data = spark.read.table("production_inference") \
    .filter("prediction_date >= current_date() - 7") \
    .toPandas()

# Test de Kolmogorov-Smirnov pour chaque feature
drift_detected = False
for col in feature_cols:
    statistic, p_value = ks_2samp(train_data[col], prod_data[col])

    if p_value < 0.05:  # Seuil de significativitÃ©
        print(f"âš ï¸ Data drift dÃ©tectÃ© sur {col}: p-value={p_value:.4f}")
        drift_detected = True

if drift_detected:
    print("DÃ©clenchement du pipeline de retraining...")
    # Trigger retraining job via API
</code></pre>
            </section>

            <section class="section">
                <div class="key-points">
                    <h3>ğŸ“Œ Points clÃ©s Ã  retenir</h3>
                    <ul>
                        <li>MLflow gÃ¨re l'intÃ©gralitÃ© du ML lifecycle : tracking, registry, serving</li>
                        <li>Tracking enregistre paramÃ¨tres, mÃ©triques, modÃ¨les et artefacts</li>
                        <li>Model Registry centralise la gestion des versions avec stages (None/Staging/Production/Archived)</li>
                        <li>AutoML accÃ©lÃ¨re le dÃ©veloppement avec tuning automatique</li>
                        <li>DÃ©ploiement flexible : batch inference ou real-time serving</li>
                        <li>MLOps workflow complet avec CI/CD et monitoring</li>
                        <li>IntÃ©gration native Databricks pour scalabilitÃ© et performance</li>
                    </ul>
                </div>
            </section>

            <section class="section">
                <div class="alert alert-success">
                    <h4>ğŸ‰ FÃ©licitations !</h4>
                    <p>Vous avez complÃ©tÃ© la formation Azure Databricks ! Vous maÃ®trisez maintenant :</p>
                    <ul>
                        <li>âœ… L'architecture et les concepts de Databricks</li>
                        <li>âœ… La configuration et gestion des clusters</li>
                        <li>âœ… Les notebooks et langages multiples</li>
                        <li>âœ… Le traitement de donnÃ©es avec Spark</li>
                        <li>âœ… Delta Lake pour des donnÃ©es fiables</li>
                        <li>âœ… L'orchestration avec Workflows</li>
                        <li>âœ… Le Machine Learning avec MLflow</li>
                    </ul>
                    <p><strong>Prochaines Ã©tapes :</strong> Mettez en pratique ces compÃ©tences sur des projets rÃ©els et explorez les fonctionnalitÃ©s avancÃ©es comme Delta Live Tables, Unity Catalog, et Lakehouse Monitoring.</p>
                </div>
            </section>
        </div>

        <nav class="nav-menu">
            <ul>
                <li><a href="../index.html">ğŸ  Accueil</a></li>
                <li><a href="partie6.html">â† Partie 6</a></li>
                <li><a href="partie7.html" class="active">Partie 7</a></li>
            </ul>
        </nav>

        <footer>
            <p>&copy; 2024 Formation Simplon - Azure Databricks</p>
        </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
