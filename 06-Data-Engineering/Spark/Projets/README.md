# Projets Pratiques Apache Spark

Ces projets vous permettent de mettre en pratique les connaissances acquises dans les modules 01 √† 10.

## Vue d'ensemble

| Projet | Niveau | Dur√©e | Concepts cl√©s |
|--------|--------|-------|---------------|
| **01-Analyse-Logs** | D√©butant | 2h | ETL, Regex, Agr√©gations |
| **02-ETL-E-commerce** | Interm√©diaire | 4h | Joins, Window functions, KPIs |
| **03-Streaming-IoT** | Avanc√© | 4h | Structured Streaming, Kafka, Real-time |

---

## Projet 01 : Analyse de Logs Web

**Objectif** : Analyser des logs Apache/Nginx pour extraire des insights.

**Ce que vous allez apprendre** :
- Parser des logs avec regex
- Nettoyer et valider des donn√©es
- Cr√©er des agr√©gations (top pages, hourly stats)
- D√©tecter des anomalies (scans, bots)

**Livrables** :
- Pipeline ETL complet
- Logs nettoy√©s (Parquet partitionn√©)
- Rapport d'analyse
- D√©tection d'anomalies

**Pr√©requis** :
- Modules 03-04 (RDDs, DataFrames)
- Module 05 (Spark SQL)
- Module 06 (ETL Pipelines)

**Dur√©e estim√©e** : 2 heures

‚û°Ô∏è [Voir le projet](./01-Analyse-Logs/README.md)

---

## Projet 02 : ETL E-commerce

**Objectif** : Pipeline ETL pour plateforme e-commerce (orders, customers, products).

**Ce que vous allez apprendre** :
- Joindre multiples sources de donn√©es
- Calculer des KPIs business (CLV, RFM)
- Cr√©er un Data Warehouse
- Segmentation clients
- Window functions avanc√©es

**Livrables** :
- Pipeline ETL multi-sources
- Data Lake (Bronze/Silver/Gold)
- Data Warehouse (Fact/Dim tables)
- Dashboard KPIs

**Pr√©requis** :
- Modules 04-05 (DataFrames, SQL)
- Module 06 (ETL)
- Module 07 (Performance)

**Dur√©e estim√©e** : 4 heures

‚û°Ô∏è [Voir le projet](./02-ETL-E-commerce/README.md)

---

## Projet 03 : Streaming IoT en Temps R√©el

**Objectif** : Traiter des donn√©es de capteurs IoT en temps r√©el avec alertes.

**Ce que vous allez apprendre** :
- Structured Streaming
- Window operations (tumbling, sliding)
- Watermarking
- D√©tection d'anomalies en temps r√©el
- Multiple sinks (Kafka, Parquet, Console)

**Livrables** :
- Pipeline streaming fonctionnel
- Syst√®me d'alertes temps r√©el
- Agr√©gations windowed
- Dashboard temps r√©el (optionnel)

**Pr√©requis** :
- Tous les modules 01-07
- Module 08 (Spark Streaming)

**Dur√©e estim√©e** : 4 heures

‚û°Ô∏è [Voir le projet](./03-Streaming-IoT/README.md)

---

## Parcours recommand√©

### Parcours D√©butant (1 semaine)

1. **Modules** : 01, 02, 04, 05, 06
2. **Projet** : 01-Analyse-Logs
3. **Objectif** : Ma√Ætriser les bases de Spark (DataFrames, SQL, ETL)

### Parcours Interm√©diaire (2 semaines)

1. **Modules** : Tous jusqu'au 07
2. **Projets** : 01 + 02
3. **Objectif** : ETL production-ready avec optimisations

### Parcours Avanc√© (3 semaines)

1. **Modules** : Tous (01-10)
2. **Projets** : Les 3 projets
3. **Objectif** : Ma√Ætriser Spark de bout en bout (batch + streaming + production)

---

## Crit√®res d'√©valuation

### Technique (60%)

- ‚úÖ Code fonctionnel et test√©
- ‚úÖ Architecture appropri√©e
- ‚úÖ Optimisations (partitioning, caching, broadcast)
- ‚úÖ Gestion des erreurs robuste
- ‚úÖ Code lisible et comment√©

### Business (25%)

- ‚úÖ R√©sultats pertinents
- ‚úÖ KPIs business corrects
- ‚úÖ Insights actionnables
- ‚úÖ Visualisations claires

### Production-ready (15%)

- ‚úÖ Logging configur√©
- ‚úÖ Configuration externalis√©e
- ‚úÖ Data quality checks
- ‚úÖ Documentation compl√®te
- ‚úÖ Tests unitaires (bonus)

---

## Extensions possibles

### Pour tous les projets

1. **CI/CD** :
   - Pipeline GitLab/GitHub Actions
   - Tests automatis√©s
   - D√©ploiement automatique

2. **Monitoring** :
   - M√©triques Prometheus
   - Dashboard Grafana
   - Alertes

3. **Machine Learning** :
   - Pr√©dictions avec MLlib
   - D√©tection d'anomalies ML
   - Recommandations

4. **Cloud** :
   - D√©ployer sur AWS EMR / GCP Dataproc / Azure Synapse
   - Utiliser S3/GCS/Blob Storage
   - Databricks

---

## Ressources

### Datasets publics

- **Logs** : [Common Crawl](https://commoncrawl.org/)
- **E-commerce** : [Kaggle E-commerce](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
- **IoT** : [UCI IoT Dataset](https://archive.ics.uci.edu/ml/datasets/Air+Quality)

### Outils utiles

- **Databricks Community Edition** : Gratuit pour tester
- **Docker Compose** : Kafka + Spark local
- **Jupyter** : Notebooks interactifs

### Communaut√©

- [Spark Users Mailing List](https://spark.apache.org/community.html)
- [Stack Overflow - apache-spark](https://stackoverflow.com/questions/tagged/apache-spark)
- [Reddit - r/apachespark](https://reddit.com/r/apachespark)

---

## Support

Pour des questions sur les projets :

1. Consultez d'abord les README de chaque projet
2. Relisez les modules correspondants
3. Utilisez la documentation Spark officielle
4. Demandez de l'aide sur les forums

---

**Bon courage pour vos projets ! üöÄ**

N'oubliez pas : l'apprentissage se fait par la pratique. N'h√©sitez pas √† exp√©rimenter, √† casser des choses, et √† apprendre de vos erreurs !
