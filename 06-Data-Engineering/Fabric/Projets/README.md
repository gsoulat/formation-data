# Projets Pratiques - Microsoft Fabric

## Vue d'ensemble

Les 6 projets pratiques de ce cours vous permettent de mettre en application l'ensemble des comp√©tences acquises dans les modules. Chaque projet est con√ßu pour √™tre **r√©aliste** et refl√©ter des sc√©narios d'entreprise r√©els.

## Structure des Projets

Chaque projet contient :
- **README.md** : Description d√©taill√©e et objectifs
- **instructions.md** : Guide pas-√†-pas
- **data/** : Jeux de donn√©es pour le projet
- **solution/** : Solution compl√®te de r√©f√©rence

## Liste des Projets

### [Projet 1 : Lakehouse ETL Pipeline](./01-Lakehouse-ETL-Pipeline/)
**Niveau :** Interm√©diaire
**Dur√©e :** 8-10 heures
**Modules concern√©s :** 02, 04, 05, 06

Construire un pipeline ETL complet avec architecture Medallion (Bronze/Silver/Gold) pour traiter des donn√©es de ventes e-commerce.

**Comp√©tences :**
- Cr√©ation de Lakehouse
- Ingestion de donn√©es multi-sources
- Transformations Spark
- Architecture Medallion
- Optimisation (partitionnement, V-Order)

---

### [Projet 2 : Real-Time Dashboard](./02-Real-Time-Dashboard/)
**Niveau :** Interm√©diaire
**Dur√©e :** 6-8 heures
**Modules concern√©s :** 08, 07

Cr√©er un dashboard temps r√©el pour monitorer des √©v√©nements IoT avec EventStream et KQL Database.

**Comp√©tences :**
- EventStream configuration
- KQL Database et queries
- Dashboards temps r√©el
- Data Activator (alertes)
- Visualisations KQL

---

### [Projet 3 : Data Warehouse Analytics](./03-Data-Warehouse-Analytics/)
**Niveau :** Interm√©diaire
**Dur√©e :** 8-10 heures
**Modules concern√©s :** 03, 07

Mod√©liser un Data Warehouse avec star schema et cr√©er des rapports Power BI avec Direct Lake.

**Comp√©tences :**
- Mod√©lisation dimensionnelle (star schema)
- T-SQL avanc√©
- Semantic models
- DAX (mesures, CALCULATE)
- Power BI reports

---

### [Projet 4 : ML Pipeline End-to-End](./04-ML-Pipeline-End-to-End/)
**Niveau :** Avanc√©
**Dur√©e :** 10-12 heures
**Modules concern√©s :** 10, 06, 04

D√©velopper un pipeline ML complet de pr√©diction de churn client, du feature engineering au d√©ploiement.

**Comp√©tences :**
- Feature engineering avec Spark
- MLflow tracking
- Model training et tuning
- Model deployment
- Batch scoring pipeline

---

### [Projet 5 : Gouvernance & S√©curit√©](./05-Gouvernance-Securite/)
**Niveau :** Avanc√©
**Dur√©e :** 6-8 heures
**Modules concern√©s :** 09, 12

Impl√©menter une strat√©gie compl√®te de s√©curit√© et gouvernance sur une architecture Fabric existante.

**Comp√©tences :**
- Row-Level Security (RLS)
- Column-Level Security (CLS)
- Sensitivity labels
- Microsoft Purview integration
- Data lineage
- Audit et compliance

---

### [Projet 6 : Migration Synapse ‚Üí Fabric](./06-Migration-Synapse-Fabric/)
**Niveau :** Expert
**Dur√©e :** 12-15 heures
**Modules concern√©s :** 14, 13, 04, 03

Planifier et ex√©cuter une migration d'une architecture Azure Synapse existante vers Microsoft Fabric.

**Comp√©tences :**
- Assessment et planning
- Migration de donn√©es (ADLS ‚Üí OneLake)
- Migration de pipelines (ADF ‚Üí Fabric)
- Migration de SQL Pools vers Warehouse
- Validation et testing
- DevOps (CI/CD)

---

## Progression Recommand√©e

### Pour d√©butants
1. Projet 1 (Lakehouse ETL)
2. Projet 3 (Data Warehouse)
3. Projet 2 (Real-Time)

### Pour profils interm√©diaires
1. Projet 1 (Lakehouse ETL)
2. Projet 4 (ML Pipeline)
3. Projet 5 (Gouvernance)

### Pour experts / pr√©paration DP-700
Tous les projets dans l'ordre 1 ‚Üí 6

## Crit√®res d'√âvaluation

Chaque projet sera √©valu√© sur :

### Fonctionnel (40%)
- ‚úÖ Tous les requis fonctionnels impl√©ment√©s
- ‚úÖ Solution fonctionnelle end-to-end
- ‚úÖ Tests de validation pass√©s

### Architecture (30%)
- ‚úÖ Best practices respect√©es
- ‚úÖ Patterns appropri√©s utilis√©s
- ‚úÖ Scalabilit√© consid√©r√©e

### Performance (15%)
- ‚úÖ Optimisations appliqu√©es
- ‚úÖ Performance acceptable
- ‚úÖ Ressources utilis√©es efficacement

### Documentation (15%)
- ‚úÖ Code comment√©
- ‚úÖ README projet
- ‚úÖ D√©cisions architecturales document√©es

## Support et Aide

### Pendant les projets
- R√©f√©rez-vous aux modules du cours
- Consultez la documentation Microsoft
- Utilisez le forum communautaire

### Bloqu√© ?
1. Relire le module correspondant
2. Consulter les hints dans instructions.md
3. V√©rifier la solution de r√©f√©rence (en dernier recours)

## Jeux de Donn√©es

Tous les datasets sont fournis dans le dossier `data/` de chaque projet.

**Sources simul√©es :**
- E-commerce sales (CSV, JSON)
- IoT sensor data (streaming)
- Customer database (SQL)
- Web logs (JSON)
- Product catalog (CSV)

**Tailles :**
- Dev/Test : ~100 MB - 1 GB
- Production simulation : 10-50 GB (optionnel)

## Livrables Attendus

Pour chaque projet, vous devez produire :

1. **Code source**
   - Notebooks (.ipynb)
   - Scripts SQL (.sql)
   - Pipelines (JSON)

2. **Documentation**
   - README du projet
   - Sch√©mas d'architecture
   - D√©cisions techniques

3. **D√©mo**
   - Dashboards fonctionnels
   - Screenshots
   - Vid√©o demo (optionnel)

## Certification DP-700

Ces projets couvrent **tous les domaines** de l'examen DP-700 :
- ‚úÖ Implement and manage (Projet 6, 5)
- ‚úÖ Ingest and transform (Projet 1, 2)
- ‚úÖ Monitor and optimize (tous projets)
- ‚úÖ Security (Projet 5)

Compl√©ter les 6 projets = pr√©paration solide pour DP-700.

## Conseils

### Gestion du temps
- Ne pas se pr√©cipiter
- Faire les projets dans l'ordre
- Prendre le temps de comprendre vs copier-coller

### Apprentissage
- Essayer seul avant de consulter la solution
- Exp√©rimenter au-del√† des requis
- Documenter les probl√®mes rencontr√©s et solutions

### Pratique
- Reproduire dans votre environnement
- Adapter avec vos propres donn√©es
- Partager avec la communaut√©

---

## Pr√™t ? Commencez par le Projet 1 ! üöÄ

[‚û°Ô∏è Projet 1 : Lakehouse ETL Pipeline](./01-Lakehouse-ETL-Pipeline/)

[‚¨ÖÔ∏è Retour au sommaire du cours](../README.md)
